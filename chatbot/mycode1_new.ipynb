{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f9c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13361bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = None\n",
    "chroma_client = None\n",
    "collection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be77b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model (BAAI/bge-base-en-v1.5)...\n",
      "This may take a moment on first run...\n",
      "Embedding model loaded successfully!\n",
      "Initializing ChromaDB...\n",
      "Persistent ChromaDB initialized with collection 'rag-chunks'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Collection(name=rag-chunks)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_embedding_model():\n",
    "    \"\"\"Load the sentence transformer model for embeddings\"\"\"\n",
    "    global embedding_model\n",
    "    print(\"Loading embedding model (BAAI/bge-base-en-v1.5)...\")\n",
    "    print(\"This may take a moment on first run...\")\n",
    "\n",
    "    # CHANGE: Use a better embedding model\n",
    "    embedding_model = SentenceTransformer('BAAI/bge-base-en-v1.5')\n",
    "    # Alternative options:\n",
    "    # embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    # embedding_model = SentenceTransformer('intfloat/e5-base-v2')\n",
    "\n",
    "    print(\"Embedding model loaded successfully!\")\n",
    "    return embedding_model\n",
    "\n",
    "\n",
    "def initialize_database(db_path=\"./vector_july22\"):\n",
    "    \"\"\"Initialize ChromaDB and create/get collection\"\"\"\n",
    "    global chroma_client, collection\n",
    "\n",
    "    print(\"Initializing ChromaDB...\")\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_july22\")\n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        name=\"rag-chunks\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # Better for semantic similarity\n",
    "    )\n",
    "    print(\"Persistent ChromaDB initialized with collection 'rag-chunks'\")\n",
    "\n",
    "    return collection\n",
    "load_embedding_model()\n",
    "initialize_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b88f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_generic_smart(pdf_path, skip_first_pages=None):\n",
    "    print(f\" Processing: {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    doc = None\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        total_pages = doc.page_count\n",
    "        \n",
    "        # Use smart detection if not specified\n",
    "        if skip_first_pages is None:\n",
    "            skip_first_pages = 7  \n",
    "            for page_num in range(5, min(20, total_pages)):\n",
    "                page = doc[page_num]\n",
    "                text = page.get_text().lower()\n",
    "                \n",
    "                if re.search(r'(chapter\\s+1|^1\\.\\s*introduction|^1\\.1\\s+|^introduction$)', text, re.MULTILINE):\n",
    "                    skip_first_pages = page_num\n",
    "                    print(f\"Found content start marker at page {page_num + 1}\")\n",
    "                    break\n",
    "        \n",
    "        print(f\" Total pages: {total_pages}\")\n",
    "        print(f\"â­  Skipping first {skip_first_pages} pages\")\n",
    "        start_page = skip_first_pages\n",
    "        pages_to_process = total_pages - start_page\n",
    "        \n",
    "        print(f\"Processing pages {start_page + 1} to {total_pages} ({pages_to_process} pages)\")\n",
    "        \n",
    "        raw_text = \"\"\n",
    "        page_texts = []\n",
    "        structured_content = []\n",
    "        for page_num in range(start_page, total_pages):\n",
    "            try:\n",
    "                page = doc[page_num]\n",
    "\n",
    "                blocks = page.get_text(\"dict\")\n",
    "                page_structured_text = []\n",
    "                current_paragraph = []\n",
    "                \n",
    "                for block in blocks[\"blocks\"]:\n",
    "                    if \"lines\" in block:\n",
    "                        for line in block[\"lines\"]:\n",
    "                            if line[\"spans\"]:\n",
    "                                text = \" \".join([span[\"text\"] for span in line[\"spans\"]])\n",
    "                                font_size = line[\"spans\"][0][\"size\"] if line[\"spans\"] else 12\n",
    "                                if (font_size > 14 or not text.strip()) and current_paragraph:\n",
    "                                    combined_text = \" \".join(current_paragraph)\n",
    "                                    if combined_text.strip():\n",
    "                                        page_structured_text.append({\n",
    "                                            \"text\": combined_text.strip(),\n",
    "                                            \"is_heading\": False,\n",
    "                                            \"font_size\": 12,\n",
    "                                            \"page\": page_num + 1\n",
    "                                        })\n",
    "                                    current_paragraph = []\n",
    "                                if font_size > 14:\n",
    "                                    page_structured_text.append({\n",
    "                                        \"text\": text.strip(),\n",
    "                                        \"is_heading\": True,\n",
    "                                        \"font_size\": font_size,\n",
    "                                        \"page\": page_num + 1\n",
    "                                    })\n",
    "                                elif text.strip():\n",
    "                                    current_paragraph.append(text.strip())\n",
    "                if current_paragraph:\n",
    "                    combined_text = \" \".join(current_paragraph)\n",
    "                    if combined_text.strip():\n",
    "                        page_structured_text.append({\n",
    "                            \"text\": combined_text.strip(),\n",
    "                            \"is_heading\": False,\n",
    "                            \"font_size\": 12,\n",
    "                            \"page\": page_num + 1\n",
    "                        })\n",
    "                page_text = page.get_text()\n",
    "                page_texts.append(page_text)\n",
    "                structured_content.extend(page_structured_text)\n",
    "                raw_text += page_text + '\\n'\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Could not read page {page_num + 1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not raw_text.strip():\n",
    "            print(\"No text found\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Extracted text from {len(page_texts)} pages\")\n",
    "        print(f\"Total text length: {len(raw_text)} characters\")\n",
    "        cleaned_text = remove_headers_footers_generic(page_texts)\n",
    "        doc.structured_content = structured_content    \n",
    "        return cleaned_text    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        if doc:\n",
    "            try:\n",
    "                doc.close()\n",
    "            except:\n",
    "                pass\n",
    "def remove_headers_footers_generic(page_texts):\n",
    "    \"\"\"Remove headers and footers based on position and repetition\"\"\"\n",
    "    print(\"Removing headers and footers generically...\")\n",
    "    \n",
    "    if not page_texts:\n",
    "        return \"\"\n",
    "    \n",
    "    # Split each page into lines\n",
    "    all_page_lines = []\n",
    "    for page_text in page_texts:\n",
    "        lines = [line.strip() for line in page_text.split('\\n') if line.strip()]\n",
    "        all_page_lines.append(lines)\n",
    "    \n",
    "    # Find common headers (first few lines that repeat across pages)\n",
    "    header_lines = find_common_position_lines(all_page_lines, position='top', max_lines=3)\n",
    "    \n",
    "    # Find common footers (last few lines that repeat across pages)\n",
    "    footer_lines = find_common_position_lines(all_page_lines, position='bottom', max_lines=3)\n",
    "    \n",
    "    print(f\"   Found {len(header_lines)} common header patterns\")\n",
    "    print(f\"   Found {len(footer_lines)} common footer patterns\")\n",
    "    \n",
    "    # Remove headers and footers from all pages\n",
    "    cleaned_pages = []\n",
    "    for page_lines in all_page_lines:\n",
    "        # Remove headers (from top)\n",
    "        start_idx = 0\n",
    "        for line in page_lines[:5]:  # Check first 5 lines\n",
    "            if line in header_lines:\n",
    "                start_idx += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Remove footers (from bottom)\n",
    "        end_idx = len(page_lines)\n",
    "        for line in reversed(page_lines[-5:]):  # Check last 5 lines\n",
    "            if line in footer_lines:\n",
    "                end_idx -= 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Keep the middle content\n",
    "        clean_lines = page_lines[start_idx:end_idx]\n",
    "        if clean_lines:\n",
    "            cleaned_pages.append('\\n'.join(clean_lines))\n",
    "    \n",
    "    final_text = '\\n\\n'.join(cleaned_pages)\n",
    "    \n",
    "    # Basic cleanup\n",
    "    final_text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', final_text)\n",
    "    final_text = re.sub(r'[ \\t]+', ' ', final_text)\n",
    "    \n",
    "    return final_text.strip()\n",
    "\n",
    "def find_common_position_lines(all_page_lines, position='top', max_lines=3):\n",
    "    \"\"\"Find lines that commonly appear at top or bottom of pages\"\"\"\n",
    "    if len(all_page_lines) < 2:\n",
    "        return set()\n",
    "    \n",
    "    # Count how often each line appears in the same position\n",
    "    line_counts = {}\n",
    "    \n",
    "    for page_lines in all_page_lines:\n",
    "        if not page_lines:\n",
    "            continue\n",
    "            \n",
    "        # Get lines from specified position\n",
    "        if position == 'top':\n",
    "            check_lines = page_lines[:max_lines]\n",
    "        else:  # bottom\n",
    "            check_lines = page_lines[-max_lines:]\n",
    "        \n",
    "        for line in check_lines:\n",
    "            if len(line) > 5:  # Ignore very short lines\n",
    "                line_counts[line] = line_counts.get(line, 0) + 1\n",
    "    \n",
    "    # Find lines that appear in at least 50% of pages\n",
    "    total_pages = len(all_page_lines)\n",
    "    threshold = max(2, total_pages * 0.5)\n",
    "    \n",
    "    common_lines = set()\n",
    "    for line, count in line_counts.items():\n",
    "        if count >= threshold:\n",
    "            common_lines.add(line)\n",
    "    \n",
    "    return common_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6bb5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_adaptive(pdf_path):\n",
    "    return extract_text_generic_smart(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1b1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chunk_quality(chunk):\n",
    "    if len(chunk) < 100:\n",
    "        return 0\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    # 1. Length score - prefer longer chunks\n",
    "    length_score = min(len(chunk) / 1500, 1.0)\n",
    "    score += length_score * 0.4\n",
    "    \n",
    "    # 2. Word count\n",
    "    words = chunk.split()\n",
    "    if len(words) > 50:\n",
    "        score += 0.3\n",
    "    \n",
    "    # 3. Sentence structure\n",
    "    sentences = re.split(r'[.!?]+', chunk)\n",
    "    complete_sentences = [s for s in sentences if len(s.strip()) > 10]\n",
    "    if len(complete_sentences) >= 2:\n",
    "        score += 0.2\n",
    "    \n",
    "    # 4. Alphabetic content ratio\n",
    "    alpha_ratio = sum(c.isalpha() or c.isspace() for c in chunk) / len(chunk)\n",
    "    score += alpha_ratio * 0.1\n",
    "    \n",
    "    return score\n",
    "\n",
    "def quality_based_chunking(text, chunk_size=2000, chunk_overlap=500, min_quality=0.3):\n",
    "    \"\"\"Create LARGER chunks with better size guarantees\"\"\"\n",
    "    print(f\"Creating quality chunks (size: {chunk_size})...\")\n",
    "    \n",
    "    # Use standard chunking with good separators\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\\n\", \"\\n\\n\", \".\\n\\n\", \".\\n\", \". \", \"\\n\", \" \"],\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    initial_chunks = splitter.split_text(text)\n",
    "    \n",
    "    # Combine small consecutive chunks\n",
    "    combined_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for chunk in initial_chunks:\n",
    "        # If current chunk + new chunk is still under 1.5x chunk_size, combine them\n",
    "        if len(current_chunk) + len(chunk) < chunk_size * 1.5:\n",
    "            if current_chunk:\n",
    "                current_chunk += \"\\n\\n\" + chunk\n",
    "            else:\n",
    "                current_chunk = chunk\n",
    "        else:\n",
    "            # Save current chunk if it's big enough\n",
    "            if current_chunk and len(current_chunk) > 500:\n",
    "                combined_chunks.append(current_chunk)\n",
    "            current_chunk = chunk\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_chunk and len(current_chunk) > 500:\n",
    "        combined_chunks.append(current_chunk)\n",
    "    \n",
    "    print(f\"   Combined {len(initial_chunks)} initial chunks into {len(combined_chunks)} chunks\")\n",
    "    \n",
    "    # Filter by quality but be less aggressive\n",
    "    quality_chunks = []\n",
    "    low_quality_chunks = []\n",
    "    quality_scores = []\n",
    "    \n",
    "    for chunk in combined_chunks:\n",
    "        chunk = chunk.strip()\n",
    "        quality = evaluate_chunk_quality(chunk)\n",
    "        \n",
    "        if quality >= min_quality or len(chunk) > 1000:  # Keep chunks > 1000 chars regardless\n",
    "            quality_chunks.append(chunk)\n",
    "            quality_scores.append(quality)\n",
    "        else:\n",
    "            low_quality_chunks.append(chunk)\n",
    "    \n",
    "    # Try to salvage low quality chunks by combining them\n",
    "    if low_quality_chunks:\n",
    "        combined_low = \" \".join(low_quality_chunks)\n",
    "        if len(combined_low) > 1000:\n",
    "            quality_chunks.append(combined_low)\n",
    "            quality_scores.append(0.5)\n",
    "    \n",
    "    avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0\n",
    "    \n",
    "    print(f\"Created {len(quality_chunks)} quality chunks\")\n",
    "    print(f\"   Average quality score: {avg_quality:.2f}\")\n",
    "    if quality_chunks:\n",
    "        avg_len = sum(len(c) for c in quality_chunks) / len(quality_chunks)\n",
    "        print(f\"   Average chunk length: {avg_len:.0f} chars\")\n",
    "        print(f\"   Min chunk length: {min(len(c) for c in quality_chunks)} chars\")\n",
    "        print(f\"   Max chunk length: {max(len(c) for c in quality_chunks)} chars\")\n",
    "    \n",
    "    return quality_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e9c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(chunks):\n",
    "    \"\"\"Generate embeddings for text chunks\"\"\"\n",
    "    print(f\"Generating embeddings for {len(chunks)} chunks...\")\n",
    "    \n",
    "    # CHANGE: Add normalize_embeddings parameter\n",
    "    embeddings = embedding_model.encode(\n",
    "        chunks, \n",
    "        show_progress_bar=True,\n",
    "        normalize_embeddings=True  # This ensures cosine similarity works better\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "    return embeddings\n",
    "def extract_metadata_from_chunk(chunk, chunk_id, pdf_name):\n",
    "    \"\"\"Extract metadata from chunk content\"\"\"\n",
    "    metadata = {\n",
    "        \"source\": pdf_name,\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"chunk_length\": len(chunk),\n",
    "        \"word_count\": len(chunk.split())\n",
    "    }\n",
    "    \n",
    "    # Try to extract chapter info\n",
    "    chapter_match = re.search(r'CHAPTER\\s+(\\d+)|Chapter\\s+(\\d+)', chunk)\n",
    "    if chapter_match:\n",
    "        metadata[\"chapter\"] = chapter_match.group(1) or chapter_match.group(2)\n",
    "    \n",
    "    # Try to extract section info\n",
    "    section_match = re.search(r'(\\d+\\.\\d+)\\s+', chunk)\n",
    "    if section_match:\n",
    "        metadata[\"section\"] = section_match.group(1)\n",
    "    \n",
    "    # Extract potential title (first line if it's short and looks like a heading)\n",
    "    first_line = chunk.split('\\n')[0].strip()\n",
    "    if len(first_line) < 100 and first_line.isupper():\n",
    "        metadata[\"potential_title\"] = first_line\n",
    "    \n",
    "    # Add preview\n",
    "    metadata[\"preview\"] = chunk[:200].replace('\\n', ' ')\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def store_chunks_in_db(chunks, embeddings, pdf_name):\n",
    "    \"\"\"Store chunks and embeddings in the vector database with rich metadata\"\"\"\n",
    "    print(f\"Storing {len(chunks)} chunks in vector database...\")\n",
    "    \n",
    "    # Prepare data for storage\n",
    "    ids = [f\"{pdf_name}_chunk_{i}\" for i in range(len(chunks))]\n",
    "    metadatas = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        metadata = extract_metadata_from_chunk(chunk, i, pdf_name)\n",
    "        metadata[\"total_chunks\"] = len(chunks)\n",
    "        metadata[\"position_ratio\"] = i / len(chunks)  # How far into doc\n",
    "        metadatas.append(metadata)\n",
    "    \n",
    "    # Add to collection\n",
    "    collection.add(\n",
    "        embeddings=embeddings.tolist(),\n",
    "        documents=chunks,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully stored {len(chunks)} chunks from {pdf_name}\")\n",
    "    print(f\"Chapters found: {len(set(m.get('chapter', 'none') for m in metadatas))}\")\n",
    "    print(f\"Sections found: {len(set(m.get('section', 'none') for m in metadatas))}\")\n",
    "    \n",
    "    return len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11501bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_pdf(pdf_path):\n",
    "    \"\"\"Process a single PDF file with duplicate checking\"\"\"\n",
    "    pdf_name = os.path.basename(pdf_path)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {pdf_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if already processed\n",
    "    try:\n",
    "        existing = collection.get(where={\"source\": pdf_name})\n",
    "        if existing['ids']:\n",
    "            print(f\" {pdf_name} already in database with {len(existing['ids'])} chunks\")\n",
    "            response = input(\"Re-process? (yes/no): \")\n",
    "            if response.lower() != 'yes':\n",
    "                return 0\n",
    "            else:\n",
    "                # Delete existing chunks\n",
    "                collection.delete(ids=existing['ids'])\n",
    "                print(f\"Deleted {len(existing['ids'])} existing chunks\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract and clean text\n",
    "        text = extract_text_adaptive(pdf_path)\n",
    "        if not text:\n",
    "            print(f\"Failed to extract meaningful text from {pdf_name}\")\n",
    "            return 0\n",
    "        \n",
    "        print(f\" Extracted text length: {len(text)} characters\")\n",
    "        \n",
    "        # Step 2: Quality-based chunking with new parameters\n",
    "        chunks = quality_based_chunking(text, chunk_size=2000, chunk_overlap=500, min_quality=0.3)\n",
    "        if not chunks:\n",
    "            print(f\" No quality chunks created from {pdf_name}\")\n",
    "            return 0\n",
    "        \n",
    "        # Step 3: Generate embeddings\n",
    "        embeddings = generate_embeddings(chunks)\n",
    "        \n",
    "        # Step 4: Store in database\n",
    "        chunk_count = store_chunks_in_db(chunks, embeddings, pdf_name)\n",
    "        \n",
    "        print(f\" Successfully processed {pdf_name}!\")\n",
    "        return chunk_count\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0\n",
    "def list_available_pdfs(folder_path=\"./pdfs\"):\n",
    "    \"\"\"List all PDF files in the folder with details\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist!\")\n",
    "        return []\n",
    "    \n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    print(f\" PDFs found in {folder_path}:\")\n",
    "    if pdf_files:\n",
    "        for i, pdf in enumerate(pdf_files, 1):\n",
    "            \n",
    "            file_path = os.path.join(folder_path, pdf)\n",
    "            file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "            print(f\"  {i}. {pdf} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        print(\"  No PDF files found!\")\n",
    "        print(f\" Please add your PDF files to the '{folder_path}' folder\")\n",
    "    \n",
    "    return pdf_files\n",
    "\n",
    "def process_all_pdfs(folder_path=\"./pdfs\"):\n",
    "    \"\"\"Process all PDF files in the folder with adaptive cleaning\"\"\"\n",
    "    pdf_files = list_available_pdfs(folder_path)\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files to process!\")\n",
    "        return [], 0\n",
    "    \n",
    "    print(f\"\\nStarting to process {len(pdf_files)} PDF files...\")\n",
    "    print(\"Using adaptive cleaning and quality-based chunking...\")\n",
    "    \n",
    "    total_chunks = 0\n",
    "    processed_files = []\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, pdf_file)\n",
    "        chunk_count = process_single_pdf(pdf_path)\n",
    "        \n",
    "        if chunk_count > 0:\n",
    "            processed_files.append((pdf_file, chunk_count))\n",
    "            total_chunks += chunk_count\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" PROCESSING COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Files processed: {len(processed_files)}/{len(pdf_files)}\")\n",
    "    print(f\"Total chunks stored: {total_chunks}\")\n",
    "    print(\"\\nSummary:\")\n",
    "    for filename, chunk_count in processed_files:\n",
    "        print(f\"{filename}: {chunk_count} chunks\")\n",
    "    \n",
    "    return processed_files, total_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84428b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this import at the top of the cell\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Initialize reranker globally\n",
    "reranker = None\n",
    "\n",
    "def initialize_reranker():\n",
    "    global reranker\n",
    "    reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    return reranker\n",
    "\n",
    "def search_similar_chunks(query, n_results=5, filter_dict=None, min_relevance=0.5):\n",
    "    print(f\"ðŸ” Searching for: '{query}'\")\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for query with normalization\n",
    "        query_embedding = embedding_model.encode([query], normalize_embeddings=True)\n",
    "        \n",
    "        # Get more candidates for reranking (3x the requested amount)\n",
    "        search_params = {\n",
    "            \"query_embeddings\": query_embedding.tolist(),\n",
    "            \"n_results\": min(n_results * 4, 40)  # Get up to 40 candidates\n",
    "        }\n",
    "        \n",
    "        if filter_dict:\n",
    "            search_params[\"where\"] = filter_dict\n",
    "            print(f\"   With filters: {filter_dict}\")\n",
    "        \n",
    "        # Search in collection\n",
    "        results = collection.query(**search_params)\n",
    "        \n",
    "        if not results['documents'][0]:\n",
    "            print(\"No results found\")\n",
    "            return []\n",
    "        \n",
    "        # Prepare candidates for reranking\n",
    "        candidates = []\n",
    "        for i, doc in enumerate(results['documents'][0]):\n",
    "            candidates.append({\n",
    "                'document': doc,\n",
    "                'metadata': results['metadatas'][0][i],\n",
    "                'initial_score': 1 - results['distances'][0][i],\n",
    "                'id': results['ids'][0][i]\n",
    "            })\n",
    "        \n",
    "        # Initialize reranker if not already done\n",
    "        global reranker\n",
    "        if reranker is None:\n",
    "            initialize_reranker()\n",
    "        \n",
    "        # Rerank using cross-encoder\n",
    "        print(f\"Reranking {len(candidates)} candidates...\")\n",
    "        pairs = [[query, c['document'][:512]] for c in candidates]  # Limit text for reranker\n",
    "        rerank_scores = reranker.predict(pairs)\n",
    "        \n",
    "        # Combine scores and filter\n",
    "        final_results = []\n",
    "        for i, candidate in enumerate(candidates):\n",
    "            # Combine initial embedding score with rerank score\n",
    "            combined_score = (candidate['initial_score'] * 0.3) + (rerank_scores[i] * 0.7)\n",
    "            \n",
    "            if combined_score >= min_relevance:\n",
    "                candidate['rerank_score'] = rerank_scores[i]\n",
    "                candidate['final_score'] = combined_score\n",
    "                final_results.append(candidate)\n",
    "        \n",
    "        # Sort by final score\n",
    "        final_results.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "        top_results = final_results[:n_results]\n",
    "        \n",
    "        if not top_results:\n",
    "            print(f\"No results above relevance threshold {min_relevance}\")\n",
    "            return []\n",
    "        \n",
    "        print(f\" Found {len(candidates)} candidates, {len(final_results)} above threshold, returning top {len(top_results)}:\")\n",
    "        \n",
    "        for i, result in enumerate(top_results):\n",
    "            metadata = result['metadata']\n",
    "            print(f\"\\n{i+1}. {metadata['source']} (ID: {result['id'][-8:]})\") \n",
    "            if metadata.get('chapter'):\n",
    "                print(f\" Chapter {metadata['chapter']}\")\n",
    "            if metadata.get('section'):\n",
    "                print(f\"  Section {metadata['section']}\")\n",
    "            print(f\"   Initial: {result['initial_score']:.3f}, Rerank: {result['rerank_score']:.3f}, Final: {result['final_score']:.3f}\")\n",
    "            print(f\"   Chunk size: {len(result['document'])} chars\")\n",
    "            print(f\"   Preview: {result['document'][:200]}...\")\n",
    "        \n",
    "        return top_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Search failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "# Update build_context_for_chatbot to handle no results better\n",
    "def build_context_for_chatbot(query, n_chunks=3, min_relevance=0.5):\n",
    "    \"\"\"Build context for chatbot from search results\"\"\"\n",
    "    results = search_similar_chunks(query, n_chunks, min_relevance=min_relevance)\n",
    "    \n",
    "    if not results:\n",
    "        return \"I couldn't find sufficiently relevant information in the documents to answer your question. Please try rephrasing your query or ask about topics covered in the uploaded documents.\"\n",
    "    \n",
    "    # Only use results with high confidence\n",
    "    high_confidence_results = [r for r in results if r['final_score'] >= 0.7]\n",
    "    \n",
    "    if high_confidence_results:\n",
    "        context = \"Based on the following highly relevant information from the documents:\\n\\n\"\n",
    "    else:\n",
    "        context = \"Based on the following potentially relevant information from the documents (moderate confidence):\\n\\n\"\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        metadata = result['metadata']\n",
    "        context += f\"[Source {i+1}: {metadata['source']}\"\n",
    "        \n",
    "        if metadata.get('chapter'):\n",
    "            context += f\", Chapter {metadata['chapter']}\"\n",
    "        if metadata.get('section'):\n",
    "            context += f\", Section {metadata['section']}\"\n",
    "        \n",
    "        context += f\" - Relevance: {result['final_score']:.2f}]\\n\"\n",
    "        context += f\"{result['document']}\\n\\n\"\n",
    "        context += \"-\" * 50 + \"\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "def get_database_stats():\n",
    "    \"\"\"Get comprehensive database statistics\"\"\"\n",
    "    try:\n",
    "        count = collection.count()\n",
    "        print(f\"Database Statistics:\")\n",
    "        print(f\" Total chunks stored: {count}\")\n",
    "        \n",
    "        if count > 0:\n",
    "            # Get sample to analyze\n",
    "            sample = collection.get(limit=min(count, 1000))\n",
    "            \n",
    "            # Count chunks per document\n",
    "            source_counts = {}\n",
    "            chapter_counts = {}\n",
    "            \n",
    "            for meta in sample['metadatas']:\n",
    "                source = meta['source']\n",
    "                source_counts[source] = source_counts.get(source, 0) + 1\n",
    "                \n",
    "                if meta.get('chapter'):\n",
    "                    chapter_key = f\"{source} - Chapter {meta['chapter']}\"\n",
    "                    chapter_counts[chapter_key] = chapter_counts.get(chapter_key, 0) + 1\n",
    "            \n",
    "            print(f\"  Documents stored: {len(source_counts)}\")\n",
    "            print(f\"   Chapters identified: {len(chapter_counts)}\")\n",
    "            print(f\"\\n  Chunks per document:\")\n",
    "            for source, chunk_count in source_counts.items():\n",
    "                print(f\"     â€¢ {source}: {chunk_count} chunks\")\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting database stats: {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def show_sample_chunks(n_samples=3):\n",
    "    \"\"\"Show sample chunks from the database\"\"\"\n",
    "    try:\n",
    "        sample = collection.peek(limit=n_samples)\n",
    "        print(f\"Sample chunks (showing {n_samples}):\")\n",
    "        \n",
    "        for i, doc in enumerate(sample['documents']):\n",
    "            metadata = sample['metadatas'][i]\n",
    "            print(f\"\\n{i+1}. {metadata['source']} (Chunk {metadata['chunk_id']})\")\n",
    "            if metadata.get('chapter'):\n",
    "                print(f\"   Chapter {metadata['chapter']}\")\n",
    "            if metadata.get('section'):\n",
    "                print(f\"   Section {metadata['section']}\")\n",
    "            print(f\"   Content: {doc[:200]}...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Error showing samples: {e}\")\n",
    "\n",
    "def answer_question(question, n_chunks=3, verbose=False):\n",
    "    \"\"\"\n",
    "    Simple Q&A function for chatbot integration\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Question: {question}\")\n",
    "    \n",
    "    # Get context\n",
    "    context = build_context_for_chatbot(question, n_chunks)\n",
    "    \n",
    "    # Format for LLM\n",
    "    prompt = f\"\"\"Based on the following context from technical documents, please answer the question.\n",
    "    \n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n Context has {len(context.split())} words\")\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Keep the other utility functions as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5191dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change working directory to the notebook location\n",
    "os.chdir(os.path.dirname(os.path.abspath(\"__file__\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e2773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PDFs found in ./pdfs:\n",
      "  1. 100_Report - Raj Kiran.pdf (1.2 MB)\n",
      "  2. 101_Report - Deepti M P.pdf (1.5 MB)\n",
      "  3. 102_Report - Navaneeth krishnan R.pdf (1.1 MB)\n",
      "  4. 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  5. 104_Report - Rahul28 Carasala.pdf (0.8 MB)\n",
      "  6. 105_Report - Mayadevi Poojari.pdf (3.9 MB)\n",
      "  7. 106_Report - Navya Pai.pdf (1.2 MB)\n",
      "  8. 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  9. 108_Report - dharini hindlatti.pdf (0.9 MB)\n",
      "  10. 109_Report - Chandra Priya.pdf (0.8 MB)\n",
      "  11. 110_Report - Vansheel Desai.pdf (1.1 MB)\n",
      "  12. 111_REPORT - Srujan Vr.pdf (1.9 MB)\n",
      "  13. 112_Report - Ashwin Sridhar.pdf (1.2 MB)\n",
      "  14. 113_Report - Sujal S.pdf (1.5 MB)\n",
      "  15. 114_Report - Aditya S Joshi.pdf (1.7 MB)\n",
      "  16. 115_Report - SHRUTI C.pdf (2.1 MB)\n",
      "  17. 116_Report - rhea sheth.pdf (3.1 MB)\n",
      "  18. 117_Report - Pratham Shetty.pdf (1.0 MB)\n",
      "  19. 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  20. 119_Report - Harshan P.pdf (2.8 MB)\n",
      "  21. 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf (1.3 MB)\n",
      "  22. 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  23. 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  24. 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf (0.9 MB)\n",
      "  25. 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  26. 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  27. 123_Report - monish d.pdf (1.0 MB)\n",
      "  28. 124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf (1.8 MB)\n",
      "  29. 125_Report - Prisha Goel.pdf (1.9 MB)\n",
      "  30. 126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  31. 127_Report - Sathvik Srikanth.pdf (1.6 MB)\n",
      "  32. 128_Report - Manish Kumar.pdf (1.0 MB)\n",
      "  33. 129_Report - Nagaraj Sori.pdf (2.6 MB)\n",
      "  34. 12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf (2.4 MB)\n",
      "  35. 130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf (1.4 MB)\n",
      "  36. 131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  37. 132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf (3.2 MB)\n",
      "  38. 133_Report - S Saujanya.pdf (1.5 MB)\n",
      "  39. 135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  40. 136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  41. 138_Report - Rajeev Kalose.pdf (3.0 MB)\n",
      "  42. 139_Report - S Sai Sree Lakshmi.pdf (1.6 MB)\n",
      "  43. 13_Report - Urvashi Bhargava.pdf (5.4 MB)\n",
      "  44. 140_Report - Sumukh Suresh.pdf (2.4 MB)\n",
      "  45. 141_Report - sooraj suresh.pdf (0.9 MB)\n",
      "  46. 142_Report - ADITYA A S 2022 Batch PES University EC.pdf (2.0 MB)\n",
      "  47. 143-reportfile - MANOJ SOLAPURE.pdf (0.7 MB)\n",
      "  48. 144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  49. 145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf (0.8 MB)\n",
      "  50. 147_REPORT - Jagdish Malagond.pdf (1.4 MB)\n",
      "  51. 148_REPORT - E. Vinith Kumar reddy.pdf (0.7 MB)\n",
      "  52. 149_Report - Tirthraj Bhalodiya.pdf (1.7 MB)\n",
      "  53. 14_Report - Varun Kamath.pdf (1.2 MB)\n",
      "  54. 150_report - Parvati Bagewadi.pdf (0.5 MB)\n",
      "  55. 151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf (1.8 MB)\n",
      "  56. 152_Report - Arun Karthik S.pdf (1.5 MB)\n",
      "  57. 155_Report - SUDEEPGOWDA A S.pdf (1.5 MB)\n",
      "  58. 15_Report - Manish I.pdf (4.3 MB)\n",
      "  59. 16_Report - pooja s.pdf (2.7 MB)\n",
      "  60. 17_Report - Sidwin S.pdf (1.6 MB)\n",
      "  61. 19_Report - Maitreyi.pdf (1.4 MB)\n",
      "  62. 1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  63. 20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf (0.8 MB)\n",
      "  64. 20_Report - NIHAL T M 2022 Batch PES University EC.pdf (0.8 MB)\n",
      "  65. 21_Report - Ranjana V.pdf (2.6 MB)\n",
      "  66. 22_Report - Siri.pdf (1.5 MB)\n",
      "  67. 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC (1).pdf (1.9 MB)\n",
      "  68. 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC.pdf (1.9 MB)\n",
      "  69. 24_Report - s s (1).pdf (1.6 MB)\n",
      "  70. 24_Report - s s.pdf (1.6 MB)\n",
      "  71. 25_REPORT - Amulya Pothumarthi.pdf (6.2 MB)\n",
      "  72. 26_report - Thaksha Ganesh (1).pdf (1.6 MB)\n",
      "  73. 26_report - Thaksha Ganesh.pdf (1.6 MB)\n",
      "  74. 27_Report - MARYAM KHAN 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  75. 30_Report - Kaashika Agrawal.pdf (2.7 MB)\n",
      "  76. 31_Report - Malavika V.pdf (3.4 MB)\n",
      "  77. 32_Report - KOTAPATI GOWTHAM SAI RAM REDDY 2022 Batch PES University EC.pdf (2.8 MB)\n",
      "  78. 33_Report - Nishanth D'Mello.pdf (1.3 MB)\n",
      "  79. 34_Report - Kushaagra Shrivastava.pdf (1.1 MB)\n",
      "  80. 36_Report - PRAJWAL V SHENOY 2022 Batch PES University EC.pdf (1.6 MB)\n",
      "  81. 37_Report - Veda P.pdf (1.3 MB)\n",
      "  82. 38_Report - Adithya Kashinath Munnoli.pdf (0.7 MB)\n",
      "  83. 39_Report - roshnav kishore.pdf (1.3 MB)\n",
      "  84. 3_Report - SHASHANK REDDY PRAKASH 2022 Batch PES University EC.pdf (7.5 MB)\n",
      "  85. 40_Report - Farhaan Ebadulla.pdf (1.3 MB)\n",
      "  86. 41_Report - Praadnya H.pdf (1.2 MB)\n",
      "  87. 42_Report - Hamsini R.pdf (2.3 MB)\n",
      "  88. 44_Report - KUSUM MANISHA 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  89. 45_Report - S.L.MEDHA 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  90. 46_Report - Meghana M.pdf (1.3 MB)\n",
      "  91. 47_Report - Neetha N Mallya.pdf (1.6 MB)\n",
      "  92. 48_Report - Archit Anand.pdf (1.1 MB)\n",
      "  93. 49_Report - NIDHI KAUSTUBH RONGHE 2022 Batch PES University EC.pdf (1.6 MB)\n",
      "  94. 4_Report - Sahana Math.pdf (4.2 MB)\n",
      "  95. 50_Report - PRIYANGSHU MAZUMDER 2022 Batch PES University EC.pdf (4.2 MB)\n",
      "  96. 52_Report - K YOGENDRA KUMAR 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  97. 53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  98. 54_Report - BHASKARLA SRI SAAHITH 2022 Batch PES University EC.pdf (2.6 MB)\n",
      "  99. 55_Report - Sudhanva Samaga.pdf (1.9 MB)\n",
      "  100. 56_Report - Ananya Bhatia (1).pdf (6.4 MB)\n",
      "  101. 56_Report - Ananya Bhatia.pdf (6.4 MB)\n",
      "  102. 59_Report - rickvibhadhini vaidyanathan.pdf (2.7 MB)\n",
      "  103. 5_Report - Pallavi Arora.pdf (2.1 MB)\n",
      "  104. 60_Report - Anirudh Sai Lanka.pdf (1.0 MB)\n",
      "  105. 60_Report - ATIF SHAIK 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  106. 61_Report.docx - Meenal B.pdf (4.4 MB)\n",
      "  107. 62_Report - HARINI ANAND 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  108. 63_Report - ADITHI BHUSHAN TURAVI 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  109. 65_Report - Gagana.pdf (0.7 MB)\n",
      "  110. 66_Report - CHETHAN V 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  111. 67_Report - NEERAJ R PATIL 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  112. 68_Report - CHINTHANA M.J 2022 Batch PES University EC.pdf (2.7 MB)\n",
      "  113. 69_Report - vishal shivkumar.pdf (1.4 MB)\n",
      "  114. 6_report - tanishka pasarad.pdf (1.9 MB)\n",
      "  115. 70_Report - Gowri Sriya.pdf (3.4 MB)\n",
      "  116. 71_REPORT - SWATHI 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  117. 72_Report - Abhilash Vinod.pdf (1.0 MB)\n",
      "  118. 74_Report - Sowmya MN PESU-EC-CSE-PES2UG22CS820.pdf (2.1 MB)\n",
      "  119. 76_Report - Ankush Nagar PESU-EC-CSE-PES2UG21CS905.pdf (0.8 MB)\n",
      "  120. 77_Report - Niveditha P.pdf (6.0 MB)\n",
      "  121. 78_Report - Oshin Saraf.pdf (2.9 MB)\n",
      "  122. 79_Report - Supratik Kar.pdf (0.7 MB)\n",
      "  123. 7_Report - khushi kiran.pdf (2.9 MB)\n",
      "  124. 80_Report - PRAGNA PRASAD 2022 Batch PES University EC.pdf (0.8 MB)\n",
      "  125. 81_Report - NALLAPULA KARTHIK 2022 Batch PES University EC.pdf (3.9 MB)\n",
      "  126. 82_Report - Rakesh Raki.pdf (1.9 MB)\n",
      "  127. 83_Report - Aaron Saldanha.pdf (0.9 MB)\n",
      "  128. 84_Report - Vismaya Ajikumar.pdf (2.6 MB)\n",
      "  129. 87_Report - AKSHIT PANDHARKAR 2022 Batch PES University EC.pdf (3.0 MB)\n",
      "  130. 88_Report - Ananya Brahmavar.pdf (0.9 MB)\n",
      "  131. 89_Report - Jay Shah.pdf (2.2 MB)\n",
      "  132. 8_Report - NIKHIL SHAJI.pdf (0.8 MB)\n",
      "  133. 90_Report - Aravind CeeBee.pdf (1.0 MB)\n",
      "  134. 91_Report - Chockalingam Annamalai.pdf (1.2 MB)\n",
      "  135. 92_Project_Report - raghavendra ambekar.pdf (2.0 MB)\n",
      "  136. 93_Report - DARSH PATEL 2022 Batch PES University EC.pdf (1.9 MB)\n",
      "  137. 94_Report - ASHWIN CHANDRASEKARAN 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  138. 95_Report - N P PRAGASHRI 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  139. 96_capstone_report - RAJGOPAL VITHAL MUTNALI 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  140. 97_Report - ALAN JOJI VELIYATH 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  141. 98_Report - KEERTHANA R 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  142. 99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf (9.3 MB)\n",
      "  143. B10_REPORT - AADITYA DEV SHARMA 2022 Batch PES University EC.pdf (0.9 MB)\n",
      "  144. capstone__team150_esa_report - SHREYAS V M 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  145. ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf (2.7 MB)\n",
      "  146. Team - 73_Report - Himanshu Nanda.pdf (1.5 MB)\n",
      "  147. Team-137_Capstone_Project_Report - Omprakash.pdf (0.7 MB)\n",
      "  148. Team-43_Report - NITISH KUMAR REDDY K.pdf (0.9 MB)\n",
      "  149. Team18_Report - Swarnika Banerjee.pdf (0.8 MB)\n",
      "  150. Team28_Report - Shweta Dash.pdf (1.4 MB)\n",
      "  151. Team35_report - ITISH RAJ SHUKLA 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  152. Team64_Report - Meera Rao.pdf (1.8 MB)\n",
      "PDFs: ['100_Report - Raj Kiran.pdf', '101_Report - Deepti M P.pdf', '102_Report - Navaneeth krishnan R.pdf', '103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf', '104_Report - Rahul28 Carasala.pdf', '105_Report - Mayadevi Poojari.pdf', '106_Report - Navya Pai.pdf', '107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf', '108_Report - dharini hindlatti.pdf', '109_Report - Chandra Priya.pdf', '110_Report - Vansheel Desai.pdf', '111_REPORT - Srujan Vr.pdf', '112_Report - Ashwin Sridhar.pdf', '113_Report - Sujal S.pdf', '114_Report - Aditya S Joshi.pdf', '115_Report - SHRUTI C.pdf', '116_Report - rhea sheth.pdf', '117_Report - Pratham Shetty.pdf', '118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf', '119_Report - Harshan P.pdf', '11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf', '11_Report - ABHINAV B V 2022 Batch PES University EC.pdf', '11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf', '120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf', '122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf', '122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf', '123_Report - monish d.pdf', '124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf', '125_Report - Prisha Goel.pdf', '126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf', '127_Report - Sathvik Srikanth.pdf', '128_Report - Manish Kumar.pdf', '129_Report - Nagaraj Sori.pdf', '12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf', '130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf', '131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf', '132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf', '133_Report - S Saujanya.pdf', '135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf', '136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf', '138_Report - Rajeev Kalose.pdf', '139_Report - S Sai Sree Lakshmi.pdf', '13_Report - Urvashi Bhargava.pdf', '140_Report - Sumukh Suresh.pdf', '141_Report - sooraj suresh.pdf', '142_Report - ADITYA A S 2022 Batch PES University EC.pdf', '143-reportfile - MANOJ SOLAPURE.pdf', '144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf', '145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf', '147_REPORT - Jagdish Malagond.pdf', '148_REPORT - E. Vinith Kumar reddy.pdf', '149_Report - Tirthraj Bhalodiya.pdf', '14_Report - Varun Kamath.pdf', '150_report - Parvati Bagewadi.pdf', '151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf', '152_Report - Arun Karthik S.pdf', '155_Report - SUDEEPGOWDA A S.pdf', '15_Report - Manish I.pdf', '16_Report - pooja s.pdf', '17_Report - Sidwin S.pdf', '19_Report - Maitreyi.pdf', '1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf', '20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf', '20_Report - NIHAL T M 2022 Batch PES University EC.pdf', '21_Report - Ranjana V.pdf', '22_Report - Siri.pdf', '23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC (1).pdf', '23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC.pdf', '24_Report - s s (1).pdf', '24_Report - s s.pdf', '25_REPORT - Amulya Pothumarthi.pdf', '26_report - Thaksha Ganesh (1).pdf', '26_report - Thaksha Ganesh.pdf', '27_Report - MARYAM KHAN 2022 Batch PES University EC.pdf', '30_Report - Kaashika Agrawal.pdf', '31_Report - Malavika V.pdf', '32_Report - KOTAPATI GOWTHAM SAI RAM REDDY 2022 Batch PES University EC.pdf', \"33_Report - Nishanth D'Mello.pdf\", '34_Report - Kushaagra Shrivastava.pdf', '36_Report - PRAJWAL V SHENOY 2022 Batch PES University EC.pdf', '37_Report - Veda P.pdf', '38_Report - Adithya Kashinath Munnoli.pdf', '39_Report - roshnav kishore.pdf', '3_Report - SHASHANK REDDY PRAKASH 2022 Batch PES University EC.pdf', '40_Report - Farhaan Ebadulla.pdf', '41_Report - Praadnya H.pdf', '42_Report - Hamsini R.pdf', '44_Report - KUSUM MANISHA 2022 Batch PES University EC.pdf', '45_Report - S.L.MEDHA 2022 Batch PES University EC.pdf', '46_Report - Meghana M.pdf', '47_Report - Neetha N Mallya.pdf', '48_Report - Archit Anand.pdf', '49_Report - NIDHI KAUSTUBH RONGHE 2022 Batch PES University EC.pdf', '4_Report - Sahana Math.pdf', '50_Report - PRIYANGSHU MAZUMDER 2022 Batch PES University EC.pdf', '52_Report - K YOGENDRA KUMAR 2022 Batch PES University EC.pdf', '53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf', '54_Report - BHASKARLA SRI SAAHITH 2022 Batch PES University EC.pdf', '55_Report - Sudhanva Samaga.pdf', '56_Report - Ananya Bhatia (1).pdf', '56_Report - Ananya Bhatia.pdf', '59_Report - rickvibhadhini vaidyanathan.pdf', '5_Report - Pallavi Arora.pdf', '60_Report - Anirudh Sai Lanka.pdf', '60_Report - ATIF SHAIK 2022 Batch PES University EC.pdf', '61_Report.docx - Meenal B.pdf', '62_Report - HARINI ANAND 2022 Batch PES University EC.pdf', '63_Report - ADITHI BHUSHAN TURAVI 2022 Batch PES University EC.pdf', '65_Report - Gagana.pdf', '66_Report - CHETHAN V 2022 Batch PES University EC.pdf', '67_Report - NEERAJ R PATIL 2022 Batch PES University EC.pdf', '68_Report - CHINTHANA M.J 2022 Batch PES University EC.pdf', '69_Report - vishal shivkumar.pdf', '6_report - tanishka pasarad.pdf', '70_Report - Gowri Sriya.pdf', '71_REPORT - SWATHI 2022 Batch PES University EC.pdf', '72_Report - Abhilash Vinod.pdf', '74_Report - Sowmya MN PESU-EC-CSE-PES2UG22CS820.pdf', '76_Report - Ankush Nagar PESU-EC-CSE-PES2UG21CS905.pdf', '77_Report - Niveditha P.pdf', '78_Report - Oshin Saraf.pdf', '79_Report - Supratik Kar.pdf', '7_Report - khushi kiran.pdf', '80_Report - PRAGNA PRASAD 2022 Batch PES University EC.pdf', '81_Report - NALLAPULA KARTHIK 2022 Batch PES University EC.pdf', '82_Report - Rakesh Raki.pdf', '83_Report - Aaron Saldanha.pdf', '84_Report - Vismaya Ajikumar.pdf', '87_Report - AKSHIT PANDHARKAR 2022 Batch PES University EC.pdf', '88_Report - Ananya Brahmavar.pdf', '89_Report - Jay Shah.pdf', '8_Report - NIKHIL SHAJI.pdf', '90_Report - Aravind CeeBee.pdf', '91_Report - Chockalingam Annamalai.pdf', '92_Project_Report - raghavendra ambekar.pdf', '93_Report - DARSH PATEL 2022 Batch PES University EC.pdf', '94_Report - ASHWIN CHANDRASEKARAN 2022 Batch PES University EC.pdf', '95_Report - N P PRAGASHRI 2022 Batch PES University EC.pdf', '96_capstone_report - RAJGOPAL VITHAL MUTNALI 2022 Batch PES University EC.pdf', '97_Report - ALAN JOJI VELIYATH 2022 Batch PES University EC.pdf', '98_Report - KEERTHANA R 2022 Batch PES University EC.pdf', '99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf', 'B10_REPORT - AADITYA DEV SHARMA 2022 Batch PES University EC.pdf', 'capstone__team150_esa_report - SHREYAS V M 2022 Batch PES University EC.pdf', 'ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf', 'Team - 73_Report - Himanshu Nanda.pdf', 'Team-137_Capstone_Project_Report - Omprakash.pdf', 'Team-43_Report - NITISH KUMAR REDDY K.pdf', 'Team18_Report - Swarnika Banerjee.pdf', 'Team28_Report - Shweta Dash.pdf', 'Team35_report - ITISH RAJ SHUKLA 2022 Batch PES University EC.pdf', 'Team64_Report - Meera Rao.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(\"PDFs:\", list_available_pdfs(\"./pdfs\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6262399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available PDFs...\n",
      " PDFs found in ./pdfs:\n",
      "  1. 100_Report - Raj Kiran.pdf (1.2 MB)\n",
      "  2. 101_Report - Deepti M P.pdf (1.5 MB)\n",
      "  3. 102_Report - Navaneeth krishnan R.pdf (1.1 MB)\n",
      "  4. 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  5. 104_Report - Rahul28 Carasala.pdf (0.8 MB)\n",
      "  6. 105_Report - Mayadevi Poojari.pdf (3.9 MB)\n",
      "  7. 106_Report - Navya Pai.pdf (1.2 MB)\n",
      "  8. 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  9. 108_Report - dharini hindlatti.pdf (0.9 MB)\n",
      "  10. 109_Report - Chandra Priya.pdf (0.8 MB)\n",
      "  11. 110_Report - Vansheel Desai.pdf (1.1 MB)\n",
      "  12. 111_REPORT - Srujan Vr.pdf (1.9 MB)\n",
      "  13. 112_Report - Ashwin Sridhar.pdf (1.2 MB)\n",
      "  14. 113_Report - Sujal S.pdf (1.5 MB)\n",
      "  15. 114_Report - Aditya S Joshi.pdf (1.7 MB)\n",
      "  16. 115_Report - SHRUTI C.pdf (2.1 MB)\n",
      "  17. 116_Report - rhea sheth.pdf (3.1 MB)\n",
      "  18. 117_Report - Pratham Shetty.pdf (1.0 MB)\n",
      "  19. 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  20. 119_Report - Harshan P.pdf (2.8 MB)\n",
      "  21. 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf (1.3 MB)\n",
      "  22. 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  23. 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  24. 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf (0.9 MB)\n",
      "  25. 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  26. 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  27. 123_Report - monish d.pdf (1.0 MB)\n",
      "  28. 124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf (1.8 MB)\n",
      "  29. 125_Report - Prisha Goel.pdf (1.9 MB)\n",
      "  30. 126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  31. 127_Report - Sathvik Srikanth.pdf (1.6 MB)\n",
      "  32. 128_Report - Manish Kumar.pdf (1.0 MB)\n",
      "  33. 129_Report - Nagaraj Sori.pdf (2.6 MB)\n",
      "  34. 12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf (2.4 MB)\n",
      "  35. 130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf (1.4 MB)\n",
      "  36. 131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  37. 132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf (3.2 MB)\n",
      "  38. 133_Report - S Saujanya.pdf (1.5 MB)\n",
      "  39. 135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  40. 136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  41. 138_Report - Rajeev Kalose.pdf (3.0 MB)\n",
      "  42. 139_Report - S Sai Sree Lakshmi.pdf (1.6 MB)\n",
      "  43. 13_Report - Urvashi Bhargava.pdf (5.4 MB)\n",
      "  44. 140_Report - Sumukh Suresh.pdf (2.4 MB)\n",
      "  45. 141_Report - sooraj suresh.pdf (0.9 MB)\n",
      "  46. 142_Report - ADITYA A S 2022 Batch PES University EC.pdf (2.0 MB)\n",
      "  47. 143-reportfile - MANOJ SOLAPURE.pdf (0.7 MB)\n",
      "  48. 144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  49. 145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf (0.8 MB)\n",
      "  50. 147_REPORT - Jagdish Malagond.pdf (1.4 MB)\n",
      "  51. 148_REPORT - E. Vinith Kumar reddy.pdf (0.7 MB)\n",
      "  52. 149_Report - Tirthraj Bhalodiya.pdf (1.7 MB)\n",
      "  53. 14_Report - Varun Kamath.pdf (1.2 MB)\n",
      "  54. 150_report - Parvati Bagewadi.pdf (0.5 MB)\n",
      "  55. 151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf (1.8 MB)\n",
      "  56. 152_Report - Arun Karthik S.pdf (1.5 MB)\n",
      "  57. 155_Report - SUDEEPGOWDA A S.pdf (1.5 MB)\n",
      "  58. 15_Report - Manish I.pdf (4.3 MB)\n",
      "  59. 16_Report - pooja s.pdf (2.7 MB)\n",
      "  60. 17_Report - Sidwin S.pdf (1.6 MB)\n",
      "  61. 19_Report - Maitreyi.pdf (1.4 MB)\n",
      "  62. 1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  63. 20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf (0.8 MB)\n",
      "  64. 20_Report - NIHAL T M 2022 Batch PES University EC.pdf (0.8 MB)\n",
      "  65. 21_Report - Ranjana V.pdf (2.6 MB)\n",
      "  66. 22_Report - Siri.pdf (1.5 MB)\n",
      "  67. 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC (1).pdf (1.9 MB)\n",
      "  68. 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC.pdf (1.9 MB)\n",
      "  69. 24_Report - s s (1).pdf (1.6 MB)\n",
      "  70. 24_Report - s s.pdf (1.6 MB)\n",
      "  71. 25_REPORT - Amulya Pothumarthi.pdf (6.2 MB)\n",
      "  72. 26_report - Thaksha Ganesh (1).pdf (1.6 MB)\n",
      "  73. 26_report - Thaksha Ganesh.pdf (1.6 MB)\n",
      "  74. 27_Report - MARYAM KHAN 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  75. 30_Report - Kaashika Agrawal.pdf (2.7 MB)\n",
      "  76. 31_Report - Malavika V.pdf (3.4 MB)\n",
      "  77. 32_Report - KOTAPATI GOWTHAM SAI RAM REDDY 2022 Batch PES University EC.pdf (2.8 MB)\n",
      "  78. 33_Report - Nishanth D'Mello.pdf (1.3 MB)\n",
      "  79. 34_Report - Kushaagra Shrivastava.pdf (1.1 MB)\n",
      "  80. 36_Report - PRAJWAL V SHENOY 2022 Batch PES University EC.pdf (1.6 MB)\n",
      "  81. 37_Report - Veda P.pdf (1.3 MB)\n",
      "  82. 38_Report - Adithya Kashinath Munnoli.pdf (0.7 MB)\n",
      "  83. 39_Report - roshnav kishore.pdf (1.3 MB)\n",
      "  84. 3_Report - SHASHANK REDDY PRAKASH 2022 Batch PES University EC.pdf (7.5 MB)\n",
      "  85. 40_Report - Farhaan Ebadulla.pdf (1.3 MB)\n",
      "  86. 41_Report - Praadnya H.pdf (1.2 MB)\n",
      "  87. 42_Report - Hamsini R.pdf (2.3 MB)\n",
      "  88. 44_Report - KUSUM MANISHA 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  89. 45_Report - S.L.MEDHA 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  90. 46_Report - Meghana M.pdf (1.3 MB)\n",
      "  91. 47_Report - Neetha N Mallya.pdf (1.6 MB)\n",
      "  92. 48_Report - Archit Anand.pdf (1.1 MB)\n",
      "  93. 49_Report - NIDHI KAUSTUBH RONGHE 2022 Batch PES University EC.pdf (1.6 MB)\n",
      "  94. 4_Report - Sahana Math.pdf (4.2 MB)\n",
      "  95. 50_Report - PRIYANGSHU MAZUMDER 2022 Batch PES University EC.pdf (4.2 MB)\n",
      "  96. 52_Report - K YOGENDRA KUMAR 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  97. 53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  98. 54_Report - BHASKARLA SRI SAAHITH 2022 Batch PES University EC.pdf (2.6 MB)\n",
      "  99. 55_Report - Sudhanva Samaga.pdf (1.9 MB)\n",
      "  100. 56_Report - Ananya Bhatia (1).pdf (6.4 MB)\n",
      "  101. 56_Report - Ananya Bhatia.pdf (6.4 MB)\n",
      "  102. 59_Report - rickvibhadhini vaidyanathan.pdf (2.7 MB)\n",
      "  103. 5_Report - Pallavi Arora.pdf (2.1 MB)\n",
      "  104. 60_Report - Anirudh Sai Lanka.pdf (1.0 MB)\n",
      "  105. 60_Report - ATIF SHAIK 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  106. 61_Report.docx - Meenal B.pdf (4.4 MB)\n",
      "  107. 62_Report - HARINI ANAND 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  108. 63_Report - ADITHI BHUSHAN TURAVI 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  109. 65_Report - Gagana.pdf (0.7 MB)\n",
      "  110. 66_Report - CHETHAN V 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  111. 67_Report - NEERAJ R PATIL 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  112. 68_Report - CHINTHANA M.J 2022 Batch PES University EC.pdf (2.7 MB)\n",
      "  113. 69_Report - vishal shivkumar.pdf (1.4 MB)\n",
      "  114. 6_report - tanishka pasarad.pdf (1.9 MB)\n",
      "  115. 70_Report - Gowri Sriya.pdf (3.4 MB)\n",
      "  116. 71_REPORT - SWATHI 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  117. 72_Report - Abhilash Vinod.pdf (1.0 MB)\n",
      "  118. 74_Report - Sowmya MN PESU-EC-CSE-PES2UG22CS820.pdf (2.1 MB)\n",
      "  119. 76_Report - Ankush Nagar PESU-EC-CSE-PES2UG21CS905.pdf (0.8 MB)\n",
      "  120. 77_Report - Niveditha P.pdf (6.0 MB)\n",
      "  121. 78_Report - Oshin Saraf.pdf (2.9 MB)\n",
      "  122. 79_Report - Supratik Kar.pdf (0.7 MB)\n",
      "  123. 7_Report - khushi kiran.pdf (2.9 MB)\n",
      "  124. 80_Report - PRAGNA PRASAD 2022 Batch PES University EC.pdf (0.8 MB)\n",
      "  125. 81_Report - NALLAPULA KARTHIK 2022 Batch PES University EC.pdf (3.9 MB)\n",
      "  126. 82_Report - Rakesh Raki.pdf (1.9 MB)\n",
      "  127. 83_Report - Aaron Saldanha.pdf (0.9 MB)\n",
      "  128. 84_Report - Vismaya Ajikumar.pdf (2.6 MB)\n",
      "  129. 87_Report - AKSHIT PANDHARKAR 2022 Batch PES University EC.pdf (3.0 MB)\n",
      "  130. 88_Report - Ananya Brahmavar.pdf (0.9 MB)\n",
      "  131. 89_Report - Jay Shah.pdf (2.2 MB)\n",
      "  132. 8_Report - NIKHIL SHAJI.pdf (0.8 MB)\n",
      "  133. 90_Report - Aravind CeeBee.pdf (1.0 MB)\n",
      "  134. 91_Report - Chockalingam Annamalai.pdf (1.2 MB)\n",
      "  135. 92_Project_Report - raghavendra ambekar.pdf (2.0 MB)\n",
      "  136. 93_Report - DARSH PATEL 2022 Batch PES University EC.pdf (1.9 MB)\n",
      "  137. 94_Report - ASHWIN CHANDRASEKARAN 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  138. 95_Report - N P PRAGASHRI 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  139. 96_capstone_report - RAJGOPAL VITHAL MUTNALI 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  140. 97_Report - ALAN JOJI VELIYATH 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  141. 98_Report - KEERTHANA R 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  142. 99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf (9.3 MB)\n",
      "  143. B10_REPORT - AADITYA DEV SHARMA 2022 Batch PES University EC.pdf (0.9 MB)\n",
      "  144. capstone__team150_esa_report - SHREYAS V M 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  145. ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf (2.7 MB)\n",
      "  146. Team - 73_Report - Himanshu Nanda.pdf (1.5 MB)\n",
      "  147. Team-137_Capstone_Project_Report - Omprakash.pdf (0.7 MB)\n",
      "  148. Team-43_Report - NITISH KUMAR REDDY K.pdf (0.9 MB)\n",
      "  149. Team18_Report - Swarnika Banerjee.pdf (0.8 MB)\n",
      "  150. Team28_Report - Shweta Dash.pdf (1.4 MB)\n",
      "  151. Team35_report - ITISH RAJ SHUKLA 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  152. Team64_Report - Meera Rao.pdf (1.8 MB)\n",
      "\n",
      " Starting processing of 152 PDF files...\n",
      " PDFs found in ./pdfs:\n",
      "  1. 100_Report - Raj Kiran.pdf (1.2 MB)\n",
      "  2. 101_Report - Deepti M P.pdf (1.5 MB)\n",
      "  3. 102_Report - Navaneeth krishnan R.pdf (1.1 MB)\n",
      "  4. 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  5. 104_Report - Rahul28 Carasala.pdf (0.8 MB)\n",
      "  6. 105_Report - Mayadevi Poojari.pdf (3.9 MB)\n",
      "  7. 106_Report - Navya Pai.pdf (1.2 MB)\n",
      "  8. 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  9. 108_Report - dharini hindlatti.pdf (0.9 MB)\n",
      "  10. 109_Report - Chandra Priya.pdf (0.8 MB)\n",
      "  11. 110_Report - Vansheel Desai.pdf (1.1 MB)\n",
      "  12. 111_REPORT - Srujan Vr.pdf (1.9 MB)\n",
      "  13. 112_Report - Ashwin Sridhar.pdf (1.2 MB)\n",
      "  14. 113_Report - Sujal S.pdf (1.5 MB)\n",
      "  15. 114_Report - Aditya S Joshi.pdf (1.7 MB)\n",
      "  16. 115_Report - SHRUTI C.pdf (2.1 MB)\n",
      "  17. 116_Report - rhea sheth.pdf (3.1 MB)\n",
      "  18. 117_Report - Pratham Shetty.pdf (1.0 MB)\n",
      "  19. 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  20. 119_Report - Harshan P.pdf (2.8 MB)\n",
      "  21. 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf (1.3 MB)\n",
      "  22. 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  23. 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  24. 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf (0.9 MB)\n",
      "  25. 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  26. 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  27. 123_Report - monish d.pdf (1.0 MB)\n",
      "  28. 124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf (1.8 MB)\n",
      "  29. 125_Report - Prisha Goel.pdf (1.9 MB)\n",
      "  30. 126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  31. 127_Report - Sathvik Srikanth.pdf (1.6 MB)\n",
      "  32. 128_Report - Manish Kumar.pdf (1.0 MB)\n",
      "  33. 129_Report - Nagaraj Sori.pdf (2.6 MB)\n",
      "  34. 12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf (2.4 MB)\n",
      "  35. 130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf (1.4 MB)\n",
      "  36. 131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  37. 132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf (3.2 MB)\n",
      "  38. 133_Report - S Saujanya.pdf (1.5 MB)\n",
      "  39. 135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  40. 136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  41. 138_Report - Rajeev Kalose.pdf (3.0 MB)\n",
      "  42. 139_Report - S Sai Sree Lakshmi.pdf (1.6 MB)\n",
      "  43. 13_Report - Urvashi Bhargava.pdf (5.4 MB)\n",
      "  44. 140_Report - Sumukh Suresh.pdf (2.4 MB)\n",
      "  45. 141_Report - sooraj suresh.pdf (0.9 MB)\n",
      "  46. 142_Report - ADITYA A S 2022 Batch PES University EC.pdf (2.0 MB)\n",
      "  47. 143-reportfile - MANOJ SOLAPURE.pdf (0.7 MB)\n",
      "  48. 144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  49. 145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf (0.8 MB)\n",
      "  50. 147_REPORT - Jagdish Malagond.pdf (1.4 MB)\n",
      "  51. 148_REPORT - E. Vinith Kumar reddy.pdf (0.7 MB)\n",
      "  52. 149_Report - Tirthraj Bhalodiya.pdf (1.7 MB)\n",
      "  53. 14_Report - Varun Kamath.pdf (1.2 MB)\n",
      "  54. 150_report - Parvati Bagewadi.pdf (0.5 MB)\n",
      "  55. 151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf (1.8 MB)\n",
      "  56. 152_Report - Arun Karthik S.pdf (1.5 MB)\n",
      "  57. 155_Report - SUDEEPGOWDA A S.pdf (1.5 MB)\n",
      "  58. 15_Report - Manish I.pdf (4.3 MB)\n",
      "  59. 16_Report - pooja s.pdf (2.7 MB)\n",
      "  60. 17_Report - Sidwin S.pdf (1.6 MB)\n",
      "  61. 19_Report - Maitreyi.pdf (1.4 MB)\n",
      "  62. 1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  63. 20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf (0.8 MB)\n",
      "  64. 20_Report - NIHAL T M 2022 Batch PES University EC.pdf (0.8 MB)\n",
      "  65. 21_Report - Ranjana V.pdf (2.6 MB)\n",
      "  66. 22_Report - Siri.pdf (1.5 MB)\n",
      "  67. 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC (1).pdf (1.9 MB)\n",
      "  68. 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC.pdf (1.9 MB)\n",
      "  69. 24_Report - s s (1).pdf (1.6 MB)\n",
      "  70. 24_Report - s s.pdf (1.6 MB)\n",
      "  71. 25_REPORT - Amulya Pothumarthi.pdf (6.2 MB)\n",
      "  72. 26_report - Thaksha Ganesh (1).pdf (1.6 MB)\n",
      "  73. 26_report - Thaksha Ganesh.pdf (1.6 MB)\n",
      "  74. 27_Report - MARYAM KHAN 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  75. 30_Report - Kaashika Agrawal.pdf (2.7 MB)\n",
      "  76. 31_Report - Malavika V.pdf (3.4 MB)\n",
      "  77. 32_Report - KOTAPATI GOWTHAM SAI RAM REDDY 2022 Batch PES University EC.pdf (2.8 MB)\n",
      "  78. 33_Report - Nishanth D'Mello.pdf (1.3 MB)\n",
      "  79. 34_Report - Kushaagra Shrivastava.pdf (1.1 MB)\n",
      "  80. 36_Report - PRAJWAL V SHENOY 2022 Batch PES University EC.pdf (1.6 MB)\n",
      "  81. 37_Report - Veda P.pdf (1.3 MB)\n",
      "  82. 38_Report - Adithya Kashinath Munnoli.pdf (0.7 MB)\n",
      "  83. 39_Report - roshnav kishore.pdf (1.3 MB)\n",
      "  84. 3_Report - SHASHANK REDDY PRAKASH 2022 Batch PES University EC.pdf (7.5 MB)\n",
      "  85. 40_Report - Farhaan Ebadulla.pdf (1.3 MB)\n",
      "  86. 41_Report - Praadnya H.pdf (1.2 MB)\n",
      "  87. 42_Report - Hamsini R.pdf (2.3 MB)\n",
      "  88. 44_Report - KUSUM MANISHA 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  89. 45_Report - S.L.MEDHA 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  90. 46_Report - Meghana M.pdf (1.3 MB)\n",
      "  91. 47_Report - Neetha N Mallya.pdf (1.6 MB)\n",
      "  92. 48_Report - Archit Anand.pdf (1.1 MB)\n",
      "  93. 49_Report - NIDHI KAUSTUBH RONGHE 2022 Batch PES University EC.pdf (1.6 MB)\n",
      "  94. 4_Report - Sahana Math.pdf (4.2 MB)\n",
      "  95. 50_Report - PRIYANGSHU MAZUMDER 2022 Batch PES University EC.pdf (4.2 MB)\n",
      "  96. 52_Report - K YOGENDRA KUMAR 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  97. 53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  98. 54_Report - BHASKARLA SRI SAAHITH 2022 Batch PES University EC.pdf (2.6 MB)\n",
      "  99. 55_Report - Sudhanva Samaga.pdf (1.9 MB)\n",
      "  100. 56_Report - Ananya Bhatia (1).pdf (6.4 MB)\n",
      "  101. 56_Report - Ananya Bhatia.pdf (6.4 MB)\n",
      "  102. 59_Report - rickvibhadhini vaidyanathan.pdf (2.7 MB)\n",
      "  103. 5_Report - Pallavi Arora.pdf (2.1 MB)\n",
      "  104. 60_Report - Anirudh Sai Lanka.pdf (1.0 MB)\n",
      "  105. 60_Report - ATIF SHAIK 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  106. 61_Report.docx - Meenal B.pdf (4.4 MB)\n",
      "  107. 62_Report - HARINI ANAND 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  108. 63_Report - ADITHI BHUSHAN TURAVI 2022 Batch PES University EC.pdf (1.3 MB)\n",
      "  109. 65_Report - Gagana.pdf (0.7 MB)\n",
      "  110. 66_Report - CHETHAN V 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  111. 67_Report - NEERAJ R PATIL 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  112. 68_Report - CHINTHANA M.J 2022 Batch PES University EC.pdf (2.7 MB)\n",
      "  113. 69_Report - vishal shivkumar.pdf (1.4 MB)\n",
      "  114. 6_report - tanishka pasarad.pdf (1.9 MB)\n",
      "  115. 70_Report - Gowri Sriya.pdf (3.4 MB)\n",
      "  116. 71_REPORT - SWATHI 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  117. 72_Report - Abhilash Vinod.pdf (1.0 MB)\n",
      "  118. 74_Report - Sowmya MN PESU-EC-CSE-PES2UG22CS820.pdf (2.1 MB)\n",
      "  119. 76_Report - Ankush Nagar PESU-EC-CSE-PES2UG21CS905.pdf (0.8 MB)\n",
      "  120. 77_Report - Niveditha P.pdf (6.0 MB)\n",
      "  121. 78_Report - Oshin Saraf.pdf (2.9 MB)\n",
      "  122. 79_Report - Supratik Kar.pdf (0.7 MB)\n",
      "  123. 7_Report - khushi kiran.pdf (2.9 MB)\n",
      "  124. 80_Report - PRAGNA PRASAD 2022 Batch PES University EC.pdf (0.8 MB)\n",
      "  125. 81_Report - NALLAPULA KARTHIK 2022 Batch PES University EC.pdf (3.9 MB)\n",
      "  126. 82_Report - Rakesh Raki.pdf (1.9 MB)\n",
      "  127. 83_Report - Aaron Saldanha.pdf (0.9 MB)\n",
      "  128. 84_Report - Vismaya Ajikumar.pdf (2.6 MB)\n",
      "  129. 87_Report - AKSHIT PANDHARKAR 2022 Batch PES University EC.pdf (3.0 MB)\n",
      "  130. 88_Report - Ananya Brahmavar.pdf (0.9 MB)\n",
      "  131. 89_Report - Jay Shah.pdf (2.2 MB)\n",
      "  132. 8_Report - NIKHIL SHAJI.pdf (0.8 MB)\n",
      "  133. 90_Report - Aravind CeeBee.pdf (1.0 MB)\n",
      "  134. 91_Report - Chockalingam Annamalai.pdf (1.2 MB)\n",
      "  135. 92_Project_Report - raghavendra ambekar.pdf (2.0 MB)\n",
      "  136. 93_Report - DARSH PATEL 2022 Batch PES University EC.pdf (1.9 MB)\n",
      "  137. 94_Report - ASHWIN CHANDRASEKARAN 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  138. 95_Report - N P PRAGASHRI 2022 Batch PES University EC.pdf (1.7 MB)\n",
      "  139. 96_capstone_report - RAJGOPAL VITHAL MUTNALI 2022 Batch PES University EC.pdf (1.0 MB)\n",
      "  140. 97_Report - ALAN JOJI VELIYATH 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  141. 98_Report - KEERTHANA R 2022 Batch PES University EC.pdf (0.6 MB)\n",
      "  142. 99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf (9.3 MB)\n",
      "  143. B10_REPORT - AADITYA DEV SHARMA 2022 Batch PES University EC.pdf (0.9 MB)\n",
      "  144. capstone__team150_esa_report - SHREYAS V M 2022 Batch PES University EC.pdf (0.5 MB)\n",
      "  145. ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf (2.7 MB)\n",
      "  146. Team - 73_Report - Himanshu Nanda.pdf (1.5 MB)\n",
      "  147. Team-137_Capstone_Project_Report - Omprakash.pdf (0.7 MB)\n",
      "  148. Team-43_Report - NITISH KUMAR REDDY K.pdf (0.9 MB)\n",
      "  149. Team18_Report - Swarnika Banerjee.pdf (0.8 MB)\n",
      "  150. Team28_Report - Shweta Dash.pdf (1.4 MB)\n",
      "  151. Team35_report - ITISH RAJ SHUKLA 2022 Batch PES University EC.pdf (1.1 MB)\n",
      "  152. Team64_Report - Meera Rao.pdf (1.8 MB)\n",
      "\n",
      "Starting to process 152 PDF files...\n",
      "Using adaptive cleaning and quality-based chunking...\n",
      "\n",
      "============================================================\n",
      "Processing: 100_Report - Raj Kiran.pdf\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100_Report - Raj Kiran.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 101_Report - Deepti M P.pdf\n",
      "============================================================\n",
      " 101_Report - Deepti M P.pdf already in database with 31 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 102_Report - Navaneeth krishnan R.pdf\n",
      "============================================================\n",
      " 102_Report - Navaneeth krishnan R.pdf already in database with 30 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf already in database with 27 chunks\n",
      "Deleted 27 existing chunks\n",
      " Processing: 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 7\n",
      " Total pages: 44\n",
      "â­  Skipping first 6 pages\n",
      "Processing pages 7 to 44 (38 pages)\n",
      "Extracted text from 38 pages\n",
      "Total text length: 55180 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 2 common footer patterns\n",
      " Extracted text length: 52153 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 34 initial chunks into 27 chunks\n",
      "Created 27 quality chunks\n",
      "   Average quality score: 0.98\n",
      "   Average chunk length: 1946 chars\n",
      "   Min chunk length: 1304 chars\n",
      "   Max chunk length: 2850 chars\n",
      "Generating embeddings for 27 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4458a8d68f54114a0f88cdfb26edcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (27, 768)\n",
      "Storing 27 chunks in vector database...\n",
      "Successfully stored 27 chunks from 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf\n",
      "Chapters found: 9\n",
      "Sections found: 14\n",
      " Successfully processed 103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 104_Report - Rahul28 Carasala.pdf\n",
      "============================================================\n",
      " 104_Report - Rahul28 Carasala.pdf already in database with 28 chunks\n",
      "Deleted 28 existing chunks\n",
      " Processing: 104_Report - Rahul28 Carasala.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 40\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 40 (35 pages)\n",
      "Extracted text from 35 pages\n",
      "Total text length: 59797 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 55618 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 45 initial chunks into 28 chunks\n",
      "Created 28 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2193 chars\n",
      "   Min chunk length: 1277 chars\n",
      "   Max chunk length: 2995 chars\n",
      "Generating embeddings for 28 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209c624c470f471a87a5060b02a5a203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (28, 768)\n",
      "Storing 28 chunks in vector database...\n",
      "Successfully stored 28 chunks from 104_Report - Rahul28 Carasala.pdf\n",
      "Chapters found: 1\n",
      "Sections found: 5\n",
      " Successfully processed 104_Report - Rahul28 Carasala.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 105_Report - Mayadevi Poojari.pdf\n",
      "============================================================\n",
      " 105_Report - Mayadevi Poojari.pdf already in database with 17 chunks\n",
      "Deleted 17 existing chunks\n",
      " Processing: 105_Report - Mayadevi Poojari.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 50\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 50 (45 pages)\n",
      "Extracted text from 45 pages\n",
      "Total text length: 51139 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 33440 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 25 initial chunks into 17 chunks\n",
      "Created 17 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2108 chars\n",
      "   Min chunk length: 1303 chars\n",
      "   Max chunk length: 2957 chars\n",
      "Generating embeddings for 17 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48e14783e0544448fd4e199ce8ba1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (17, 768)\n",
      "Storing 17 chunks in vector database...\n",
      "Successfully stored 17 chunks from 105_Report - Mayadevi Poojari.pdf\n",
      "Chapters found: 8\n",
      "Sections found: 3\n",
      " Successfully processed 105_Report - Mayadevi Poojari.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 106_Report - Navya Pai.pdf\n",
      "============================================================\n",
      " 106_Report - Navya Pai.pdf already in database with 19 chunks\n",
      "Deleted 19 existing chunks\n",
      " Processing: 106_Report - Navya Pai.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 48\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 48 (43 pages)\n",
      "Extracted text from 43 pages\n",
      "Total text length: 50857 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 39117 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 28 initial chunks into 19 chunks\n",
      "Created 19 quality chunks\n",
      "   Average quality score: 0.98\n",
      "   Average chunk length: 2113 chars\n",
      "   Min chunk length: 1146 chars\n",
      "   Max chunk length: 2969 chars\n",
      "Generating embeddings for 19 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e1568dccbd4df0aed9bae9ef52db34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (19, 768)\n",
      "Storing 19 chunks in vector database...\n",
      "Successfully stored 19 chunks from 106_Report - Navya Pai.pdf\n",
      "Chapters found: 8\n",
      "Sections found: 13\n",
      " Successfully processed 106_Report - Navya Pai.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf already in database with 25 chunks\n",
      "Deleted 25 existing chunks\n",
      " Processing: 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 62\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 62 (57 pages)\n",
      "Extracted text from 57 pages\n",
      "Total text length: 63445 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 49424 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 35 initial chunks into 25 chunks\n",
      "Created 25 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2013 chars\n",
      "   Min chunk length: 1266 chars\n",
      "   Max chunk length: 2874 chars\n",
      "Generating embeddings for 25 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41c11c16da74197b7df0e398c1b3011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (25, 768)\n",
      "Storing 25 chunks in vector database...\n",
      "Successfully stored 25 chunks from 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf\n",
      "Chapters found: 8\n",
      "Sections found: 19\n",
      " Successfully processed 107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 108_Report - dharini hindlatti.pdf\n",
      "============================================================\n",
      " 108_Report - dharini hindlatti.pdf already in database with 14 chunks\n",
      "Deleted 14 existing chunks\n",
      " Processing: 108_Report - dharini hindlatti.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 42\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 42 (37 pages)\n",
      "Extracted text from 37 pages\n",
      "Total text length: 32022 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 0 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 30580 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 21 initial chunks into 14 chunks\n",
      "Created 14 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2209 chars\n",
      "   Min chunk length: 1146 chars\n",
      "   Max chunk length: 2933 chars\n",
      "Generating embeddings for 14 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5331973542e4d4e85c053c782c70fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (14, 768)\n",
      "Storing 14 chunks in vector database...\n",
      "Successfully stored 14 chunks from 108_Report - dharini hindlatti.pdf\n",
      "Chapters found: 1\n",
      "Sections found: 11\n",
      " Successfully processed 108_Report - dharini hindlatti.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 109_Report - Chandra Priya.pdf\n",
      "============================================================\n",
      " 109_Report - Chandra Priya.pdf already in database with 22 chunks\n",
      "Deleted 22 existing chunks\n",
      " Processing: 109_Report - Chandra Priya.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 48\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 48 (43 pages)\n",
      "Extracted text from 43 pages\n",
      "Total text length: 45668 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 1 common header patterns\n",
      "   Found 2 common footer patterns\n",
      " Extracted text length: 44118 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 31 initial chunks into 22 chunks\n",
      "Created 22 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2023 chars\n",
      "   Min chunk length: 1337 chars\n",
      "   Max chunk length: 2817 chars\n",
      "Generating embeddings for 22 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5d5213a599495ebdb79bbeb72c5e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (22, 768)\n",
      "Storing 22 chunks in vector database...\n",
      "Successfully stored 22 chunks from 109_Report - Chandra Priya.pdf\n",
      "Chapters found: 1\n",
      "Sections found: 8\n",
      " Successfully processed 109_Report - Chandra Priya.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 110_Report - Vansheel Desai.pdf\n",
      "============================================================\n",
      " 110_Report - Vansheel Desai.pdf already in database with 16 chunks\n",
      "Deleted 16 existing chunks\n",
      " Processing: 110_Report - Vansheel Desai.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 44\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 44 (39 pages)\n",
      "Extracted text from 39 pages\n",
      "Total text length: 38526 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 0 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 36561 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 28 initial chunks into 16 chunks\n",
      "Created 16 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2294 chars\n",
      "   Min chunk length: 1148 chars\n",
      "   Max chunk length: 2962 chars\n",
      "Generating embeddings for 16 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5067ea48da3649f7881a88942730dd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (16, 768)\n",
      "Storing 16 chunks in vector database...\n",
      "Successfully stored 16 chunks from 110_Report - Vansheel Desai.pdf\n",
      "Chapters found: 1\n",
      "Sections found: 11\n",
      " Successfully processed 110_Report - Vansheel Desai.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 111_REPORT - Srujan Vr.pdf\n",
      "============================================================\n",
      " 111_REPORT - Srujan Vr.pdf already in database with 13 chunks\n",
      "Deleted 13 existing chunks\n",
      " Processing: 111_REPORT - Srujan Vr.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 40\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 40 (35 pages)\n",
      "Extracted text from 35 pages\n",
      "Total text length: 33416 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 26780 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 19 initial chunks into 13 chunks\n",
      "Created 13 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2118 chars\n",
      "   Min chunk length: 1493 chars\n",
      "   Max chunk length: 2750 chars\n",
      "Generating embeddings for 13 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7070926c3f48719891b94601aad4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (13, 768)\n",
      "Storing 13 chunks in vector database...\n",
      "Successfully stored 13 chunks from 111_REPORT - Srujan Vr.pdf\n",
      "Chapters found: 5\n",
      "Sections found: 8\n",
      " Successfully processed 111_REPORT - Srujan Vr.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 112_Report - Ashwin Sridhar.pdf\n",
      "============================================================\n",
      " 112_Report - Ashwin Sridhar.pdf already in database with 14 chunks\n",
      "Deleted 14 existing chunks\n",
      " Processing: 112_Report - Ashwin Sridhar.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 44\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 44 (39 pages)\n",
      "Extracted text from 39 pages\n",
      "Total text length: 36407 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 0 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 26564 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 19 initial chunks into 14 chunks\n",
      "Created 14 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2026 chars\n",
      "   Min chunk length: 1490 chars\n",
      "   Max chunk length: 2973 chars\n",
      "Generating embeddings for 14 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9ff5678b3147d48351961f4800e1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (14, 768)\n",
      "Storing 14 chunks in vector database...\n",
      "Successfully stored 14 chunks from 112_Report - Ashwin Sridhar.pdf\n",
      "Chapters found: 9\n",
      "Sections found: 12\n",
      " Successfully processed 112_Report - Ashwin Sridhar.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 113_Report - Sujal S.pdf\n",
      "============================================================\n",
      " 113_Report - Sujal S.pdf already in database with 37 chunks\n",
      "Deleted 37 existing chunks\n",
      " Processing: 113_Report - Sujal S.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 62\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 62 (57 pages)\n",
      "Extracted text from 57 pages\n",
      "Total text length: 78971 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 72430 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 51 initial chunks into 37 chunks\n",
      "Created 37 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2032 chars\n",
      "   Min chunk length: 1328 chars\n",
      "   Max chunk length: 2895 chars\n",
      "Generating embeddings for 37 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644fc194cff84721bec912d56c088f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (37, 768)\n",
      "Storing 37 chunks in vector database...\n",
      "Successfully stored 37 chunks from 113_Report - Sujal S.pdf\n",
      "Chapters found: 1\n",
      "Sections found: 21\n",
      " Successfully processed 113_Report - Sujal S.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 114_Report - Aditya S Joshi.pdf\n",
      "============================================================\n",
      " 114_Report - Aditya S Joshi.pdf already in database with 39 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 115_Report - SHRUTI C.pdf\n",
      "============================================================\n",
      " 115_Report - SHRUTI C.pdf already in database with 20 chunks\n",
      "Deleted 20 existing chunks\n",
      " Processing: 115_Report - SHRUTI C.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 48\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 48 (43 pages)\n",
      "Extracted text from 43 pages\n",
      "Total text length: 51846 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 40001 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 27 initial chunks into 20 chunks\n",
      "Created 20 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2028 chars\n",
      "   Min chunk length: 1363 chars\n",
      "   Max chunk length: 3000 chars\n",
      "Generating embeddings for 20 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ccd8291ec2409a99af9d103f2eaa21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (20, 768)\n",
      "Storing 20 chunks in vector database...\n",
      "Successfully stored 20 chunks from 115_Report - SHRUTI C.pdf\n",
      "Chapters found: 8\n",
      "Sections found: 11\n",
      " Successfully processed 115_Report - SHRUTI C.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 116_Report - rhea sheth.pdf\n",
      "============================================================\n",
      " 116_Report - rhea sheth.pdf already in database with 20 chunks\n",
      "Deleted 20 existing chunks\n",
      " Processing: 116_Report - rhea sheth.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 38\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 38 (33 pages)\n",
      "Extracted text from 33 pages\n",
      "Total text length: 44392 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 39001 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 25 initial chunks into 20 chunks\n",
      "Created 20 quality chunks\n",
      "   Average quality score: 1.00\n",
      "   Average chunk length: 1964 chars\n",
      "   Min chunk length: 1578 chars\n",
      "   Max chunk length: 2806 chars\n",
      "Generating embeddings for 20 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc57ddfbcd24137a2a5d09bc1827a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (20, 768)\n",
      "Storing 20 chunks in vector database...\n",
      "Successfully stored 20 chunks from 116_Report - rhea sheth.pdf\n",
      "Chapters found: 8\n",
      "Sections found: 17\n",
      " Successfully processed 116_Report - rhea sheth.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 117_Report - Pratham Shetty.pdf\n",
      "============================================================\n",
      " 117_Report - Pratham Shetty.pdf already in database with 19 chunks\n",
      "Deleted 19 existing chunks\n",
      " Processing: 117_Report - Pratham Shetty.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 40\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 40 (35 pages)\n",
      "Extracted text from 35 pages\n",
      "Total text length: 43860 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 37011 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 25 initial chunks into 19 chunks\n",
      "Created 19 quality chunks\n",
      "   Average quality score: 0.98\n",
      "   Average chunk length: 1977 chars\n",
      "   Min chunk length: 1143 chars\n",
      "   Max chunk length: 2916 chars\n",
      "Generating embeddings for 19 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4992112a51bb42d78f2bc61c79df15fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (19, 768)\n",
      "Storing 19 chunks in vector database...\n",
      "Successfully stored 19 chunks from 117_Report - Pratham Shetty.pdf\n",
      "Chapters found: 6\n",
      "Sections found: 13\n",
      " Successfully processed 117_Report - Pratham Shetty.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf already in database with 14 chunks\n",
      "Deleted 14 existing chunks\n",
      " Processing: 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 40\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 40 (35 pages)\n",
      "Extracted text from 35 pages\n",
      "Total text length: 37634 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 28427 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 21 initial chunks into 14 chunks\n",
      "Created 14 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2080 chars\n",
      "   Min chunk length: 1171 chars\n",
      "   Max chunk length: 2968 chars\n",
      "Generating embeddings for 14 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59ce98ff25c46e98255baf7f38614e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (14, 768)\n",
      "Storing 14 chunks in vector database...\n",
      "Successfully stored 14 chunks from 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf\n",
      "Chapters found: 7\n",
      "Sections found: 9\n",
      " Successfully processed 118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 119_Report - Harshan P.pdf\n",
      "============================================================\n",
      " 119_Report - Harshan P.pdf already in database with 23 chunks\n",
      "Deleted 23 existing chunks\n",
      " Processing: 119_Report - Harshan P.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 61\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 61 (56 pages)\n",
      "Extracted text from 56 pages\n",
      "Total text length: 58976 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 2 common footer patterns\n",
      " Extracted text length: 48787 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 37 initial chunks into 23 chunks\n",
      "Created 23 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2185 chars\n",
      "   Min chunk length: 1347 chars\n",
      "   Max chunk length: 2877 chars\n",
      "Generating embeddings for 23 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d3f74a62324856b503f901f3a0b758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (23, 768)\n",
      "Storing 23 chunks in vector database...\n",
      "Successfully stored 23 chunks from 119_Report - Harshan P.pdf\n",
      "Chapters found: 9\n",
      "Sections found: 16\n",
      " Successfully processed 119_Report - Harshan P.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf\n",
      "============================================================\n",
      " 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf already in database with 27 chunks\n",
      "Deleted 27 existing chunks\n",
      " Processing: 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf\n",
      "Found content start marker at page 7\n",
      " Total pages: 51\n",
      "â­  Skipping first 6 pages\n",
      "Processing pages 7 to 51 (45 pages)\n",
      "Extracted text from 45 pages\n",
      "Total text length: 60280 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 56066 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 43 initial chunks into 27 chunks\n",
      "Created 27 quality chunks\n",
      "   Average quality score: 1.00\n",
      "   Average chunk length: 2198 chars\n",
      "   Min chunk length: 1479 chars\n",
      "   Max chunk length: 2876 chars\n",
      "Generating embeddings for 27 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525daa5940d14e849e96eab2c5783917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (27, 768)\n",
      "Storing 27 chunks in vector database...\n",
      "Successfully stored 27 chunks from 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf\n",
      "Chapters found: 7\n",
      "Sections found: 14\n",
      " Successfully processed 11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf already in database with 27 chunks\n",
      "Deleted 27 existing chunks\n",
      " Processing: 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 7\n",
      " Total pages: 51\n",
      "â­  Skipping first 6 pages\n",
      "Processing pages 7 to 51 (45 pages)\n",
      "Extracted text from 45 pages\n",
      "Total text length: 60280 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 56066 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 43 initial chunks into 27 chunks\n",
      "Created 27 quality chunks\n",
      "   Average quality score: 1.00\n",
      "   Average chunk length: 2198 chars\n",
      "   Min chunk length: 1479 chars\n",
      "   Max chunk length: 2876 chars\n",
      "Generating embeddings for 27 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d421fafb064c79ba955150de70d1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (27, 768)\n",
      "Storing 27 chunks in vector database...\n",
      "Successfully stored 27 chunks from 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf\n",
      "Chapters found: 7\n",
      "Sections found: 14\n",
      " Successfully processed 11_Report - ABHINAV B V 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf already in database with 27 chunks\n",
      "Deleted 27 existing chunks\n",
      " Processing: 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 7\n",
      " Total pages: 51\n",
      "â­  Skipping first 6 pages\n",
      "Processing pages 7 to 51 (45 pages)\n",
      "Extracted text from 45 pages\n",
      "Total text length: 60280 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 56066 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 43 initial chunks into 27 chunks\n",
      "Created 27 quality chunks\n",
      "   Average quality score: 1.00\n",
      "   Average chunk length: 2198 chars\n",
      "   Min chunk length: 1479 chars\n",
      "   Max chunk length: 2876 chars\n",
      "Generating embeddings for 27 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa5cedea81428ca4c048a9069a62db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (27, 768)\n",
      "Storing 27 chunks in vector database...\n",
      "Successfully stored 27 chunks from 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf\n",
      "Chapters found: 7\n",
      "Sections found: 14\n",
      " Successfully processed 11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf already in database with 16 chunks\n",
      "Deleted 16 existing chunks\n",
      " Processing: 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 41\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 41 (36 pages)\n",
      "Extracted text from 36 pages\n",
      "Total text length: 37749 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 3 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 32528 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 23 initial chunks into 16 chunks\n",
      "Created 16 quality chunks\n",
      "   Average quality score: 0.96\n",
      "   Average chunk length: 2081 chars\n",
      "   Min chunk length: 530 chars\n",
      "   Max chunk length: 2869 chars\n",
      "Generating embeddings for 16 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7003ef443d2344b2aaf5b55120b2edc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (16, 768)\n",
      "Storing 16 chunks in vector database...\n",
      "Successfully stored 16 chunks from 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf\n",
      "Chapters found: 1\n",
      "Sections found: 10\n",
      " Successfully processed 120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf already in database with 15 chunks\n",
      "Deleted 15 existing chunks\n",
      " Processing: 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 41\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 41 (36 pages)\n",
      "Extracted text from 36 pages\n",
      "Total text length: 43866 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 34833 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 25 initial chunks into 15 chunks\n",
      "Created 15 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2325 chars\n",
      "   Min chunk length: 1317 chars\n",
      "   Max chunk length: 2990 chars\n",
      "Generating embeddings for 15 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f386f5398a744776a435713d778c4401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (15, 768)\n",
      "Storing 15 chunks in vector database...\n",
      "Successfully stored 15 chunks from 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf\n",
      "Chapters found: 7\n",
      "Sections found: 13\n",
      " Successfully processed 122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf already in database with 19 chunks\n",
      "Deleted 19 existing chunks\n",
      " Processing: 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 45\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 45 (40 pages)\n",
      "Extracted text from 40 pages\n",
      "Total text length: 44206 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 2 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 41366 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 30 initial chunks into 19 chunks\n",
      "Created 19 quality chunks\n",
      "   Average quality score: 0.99\n",
      "   Average chunk length: 2181 chars\n",
      "   Min chunk length: 1344 chars\n",
      "   Max chunk length: 2991 chars\n",
      "Generating embeddings for 19 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca12e1fbae2b46b4a399c4e2fe1b7a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (19, 768)\n",
      "Storing 19 chunks in vector database...\n",
      "Successfully stored 19 chunks from 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf\n",
      "Chapters found: 6\n",
      "Sections found: 16\n",
      " Successfully processed 122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 123_Report - monish d.pdf\n",
      "============================================================\n",
      " 123_Report - monish d.pdf already in database with 30 chunks\n",
      "Deleted 30 existing chunks\n",
      " Processing: 123_Report - monish d.pdf\n",
      "Found content start marker at page 6\n",
      " Total pages: 42\n",
      "â­  Skipping first 5 pages\n",
      "Processing pages 6 to 42 (37 pages)\n",
      "Extracted text from 37 pages\n",
      "Total text length: 64248 characters\n",
      "Removing headers and footers generically...\n",
      "   Found 0 common header patterns\n",
      "   Found 0 common footer patterns\n",
      " Extracted text length: 61704 characters\n",
      "Creating quality chunks (size: 2000)...\n",
      "   Combined 47 initial chunks into 30 chunks\n",
      "Created 30 quality chunks\n",
      "   Average quality score: 0.98\n",
      "   Average chunk length: 2162 chars\n",
      "   Min chunk length: 606 chars\n",
      "   Max chunk length: 2990 chars\n",
      "Generating embeddings for 30 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd3086242c34c3db6d80c1da68322f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (30, 768)\n",
      "Storing 30 chunks in vector database...\n",
      "Successfully stored 30 chunks from 123_Report - monish d.pdf\n",
      "Chapters found: 6\n",
      "Sections found: 15\n",
      " Successfully processed 123_Report - monish d.pdf!\n",
      "\n",
      "============================================================\n",
      "Processing: 124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 125_Report - Prisha Goel.pdf\n",
      "============================================================\n",
      " 125_Report - Prisha Goel.pdf already in database with 15 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 127_Report - Sathvik Srikanth.pdf\n",
      "============================================================\n",
      " 127_Report - Sathvik Srikanth.pdf already in database with 28 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 128_Report - Manish Kumar.pdf\n",
      "============================================================\n",
      " 128_Report - Manish Kumar.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 129_Report - Nagaraj Sori.pdf\n",
      "============================================================\n",
      " 129_Report - Nagaraj Sori.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf already in database with 34 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf already in database with 16 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf already in database with 27 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 133_Report - S Saujanya.pdf\n",
      "============================================================\n",
      " 133_Report - S Saujanya.pdf already in database with 27 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf already in database with 32 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 138_Report - Rajeev Kalose.pdf\n",
      "============================================================\n",
      " 138_Report - Rajeev Kalose.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 139_Report - S Sai Sree Lakshmi.pdf\n",
      "============================================================\n",
      " 139_Report - S Sai Sree Lakshmi.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 13_Report - Urvashi Bhargava.pdf\n",
      "============================================================\n",
      " 13_Report - Urvashi Bhargava.pdf already in database with 14 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 140_Report - Sumukh Suresh.pdf\n",
      "============================================================\n",
      " 140_Report - Sumukh Suresh.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 141_Report - sooraj suresh.pdf\n",
      "============================================================\n",
      " 141_Report - sooraj suresh.pdf already in database with 15 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 142_Report - ADITYA A S 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 142_Report - ADITYA A S 2022 Batch PES University EC.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 143-reportfile - MANOJ SOLAPURE.pdf\n",
      "============================================================\n",
      " 143-reportfile - MANOJ SOLAPURE.pdf already in database with 30 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf\n",
      "============================================================\n",
      " 145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf already in database with 30 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 147_REPORT - Jagdish Malagond.pdf\n",
      "============================================================\n",
      " 147_REPORT - Jagdish Malagond.pdf already in database with 26 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 148_REPORT - E. Vinith Kumar reddy.pdf\n",
      "============================================================\n",
      " 148_REPORT - E. Vinith Kumar reddy.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 149_Report - Tirthraj Bhalodiya.pdf\n",
      "============================================================\n",
      " 149_Report - Tirthraj Bhalodiya.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 14_Report - Varun Kamath.pdf\n",
      "============================================================\n",
      " 14_Report - Varun Kamath.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 150_report - Parvati Bagewadi.pdf\n",
      "============================================================\n",
      " 150_report - Parvati Bagewadi.pdf already in database with 16 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 152_Report - Arun Karthik S.pdf\n",
      "============================================================\n",
      " 152_Report - Arun Karthik S.pdf already in database with 28 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 155_Report - SUDEEPGOWDA A S.pdf\n",
      "============================================================\n",
      " 155_Report - SUDEEPGOWDA A S.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 15_Report - Manish I.pdf\n",
      "============================================================\n",
      " 15_Report - Manish I.pdf already in database with 34 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 16_Report - pooja s.pdf\n",
      "============================================================\n",
      " 16_Report - pooja s.pdf already in database with 16 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 17_Report - Sidwin S.pdf\n",
      "============================================================\n",
      " 17_Report - Sidwin S.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 19_Report - Maitreyi.pdf\n",
      "============================================================\n",
      " 19_Report - Maitreyi.pdf already in database with 27 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf already in database with 27 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf\n",
      "============================================================\n",
      " 20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 20_Report - NIHAL T M 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 20_Report - NIHAL T M 2022 Batch PES University EC.pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 21_Report - Ranjana V.pdf\n",
      "============================================================\n",
      " 21_Report - Ranjana V.pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 22_Report - Siri.pdf\n",
      "============================================================\n",
      " 22_Report - Siri.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC (1).pdf\n",
      "============================================================\n",
      " 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC (1).pdf already in database with 30 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 23_Report - NISHTHA PANCHRATNA 2022 Batch PES University EC.pdf already in database with 30 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 24_Report - s s (1).pdf\n",
      "============================================================\n",
      " 24_Report - s s (1).pdf already in database with 18 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 24_Report - s s.pdf\n",
      "============================================================\n",
      " 24_Report - s s.pdf already in database with 18 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 25_REPORT - Amulya Pothumarthi.pdf\n",
      "============================================================\n",
      " 25_REPORT - Amulya Pothumarthi.pdf already in database with 11 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 26_report - Thaksha Ganesh (1).pdf\n",
      "============================================================\n",
      " 26_report - Thaksha Ganesh (1).pdf already in database with 35 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 26_report - Thaksha Ganesh.pdf\n",
      "============================================================\n",
      " 26_report - Thaksha Ganesh.pdf already in database with 35 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 27_Report - MARYAM KHAN 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 27_Report - MARYAM KHAN 2022 Batch PES University EC.pdf already in database with 36 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 30_Report - Kaashika Agrawal.pdf\n",
      "============================================================\n",
      " 30_Report - Kaashika Agrawal.pdf already in database with 26 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 31_Report - Malavika V.pdf\n",
      "============================================================\n",
      " 31_Report - Malavika V.pdf already in database with 28 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 32_Report - KOTAPATI GOWTHAM SAI RAM REDDY 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 32_Report - KOTAPATI GOWTHAM SAI RAM REDDY 2022 Batch PES University EC.pdf already in database with 14 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 33_Report - Nishanth D'Mello.pdf\n",
      "============================================================\n",
      " 33_Report - Nishanth D'Mello.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 34_Report - Kushaagra Shrivastava.pdf\n",
      "============================================================\n",
      " 34_Report - Kushaagra Shrivastava.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 36_Report - PRAJWAL V SHENOY 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 36_Report - PRAJWAL V SHENOY 2022 Batch PES University EC.pdf already in database with 33 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 37_Report - Veda P.pdf\n",
      "============================================================\n",
      " 37_Report - Veda P.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 38_Report - Adithya Kashinath Munnoli.pdf\n",
      "============================================================\n",
      " 38_Report - Adithya Kashinath Munnoli.pdf already in database with 28 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 39_Report - roshnav kishore.pdf\n",
      "============================================================\n",
      " 39_Report - roshnav kishore.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 3_Report - SHASHANK REDDY PRAKASH 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 3_Report - SHASHANK REDDY PRAKASH 2022 Batch PES University EC.pdf already in database with 33 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 40_Report - Farhaan Ebadulla.pdf\n",
      "============================================================\n",
      " 40_Report - Farhaan Ebadulla.pdf already in database with 18 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 41_Report - Praadnya H.pdf\n",
      "============================================================\n",
      " 41_Report - Praadnya H.pdf already in database with 14 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 42_Report - Hamsini R.pdf\n",
      "============================================================\n",
      " 42_Report - Hamsini R.pdf already in database with 29 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 44_Report - KUSUM MANISHA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 44_Report - KUSUM MANISHA 2022 Batch PES University EC.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 45_Report - S.L.MEDHA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 45_Report - S.L.MEDHA 2022 Batch PES University EC.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 46_Report - Meghana M.pdf\n",
      "============================================================\n",
      " 46_Report - Meghana M.pdf already in database with 30 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 47_Report - Neetha N Mallya.pdf\n",
      "============================================================\n",
      " 47_Report - Neetha N Mallya.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 48_Report - Archit Anand.pdf\n",
      "============================================================\n",
      " 48_Report - Archit Anand.pdf already in database with 29 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 49_Report - NIDHI KAUSTUBH RONGHE 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 49_Report - NIDHI KAUSTUBH RONGHE 2022 Batch PES University EC.pdf already in database with 24 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 4_Report - Sahana Math.pdf\n",
      "============================================================\n",
      " 4_Report - Sahana Math.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 50_Report - PRIYANGSHU MAZUMDER 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 50_Report - PRIYANGSHU MAZUMDER 2022 Batch PES University EC.pdf already in database with 34 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 52_Report - K YOGENDRA KUMAR 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 52_Report - K YOGENDRA KUMAR 2022 Batch PES University EC.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 54_Report - BHASKARLA SRI SAAHITH 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 54_Report - BHASKARLA SRI SAAHITH 2022 Batch PES University EC.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 55_Report - Sudhanva Samaga.pdf\n",
      "============================================================\n",
      " 55_Report - Sudhanva Samaga.pdf already in database with 26 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 56_Report - Ananya Bhatia (1).pdf\n",
      "============================================================\n",
      " 56_Report - Ananya Bhatia (1).pdf already in database with 35 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 56_Report - Ananya Bhatia.pdf\n",
      "============================================================\n",
      " 56_Report - Ananya Bhatia.pdf already in database with 35 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 59_Report - rickvibhadhini vaidyanathan.pdf\n",
      "============================================================\n",
      " 59_Report - rickvibhadhini vaidyanathan.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 5_Report - Pallavi Arora.pdf\n",
      "============================================================\n",
      " 5_Report - Pallavi Arora.pdf already in database with 37 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 60_Report - Anirudh Sai Lanka.pdf\n",
      "============================================================\n",
      " 60_Report - Anirudh Sai Lanka.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 60_Report - ATIF SHAIK 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 60_Report - ATIF SHAIK 2022 Batch PES University EC.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 61_Report.docx - Meenal B.pdf\n",
      "============================================================\n",
      " 61_Report.docx - Meenal B.pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 62_Report - HARINI ANAND 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 62_Report - HARINI ANAND 2022 Batch PES University EC.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 63_Report - ADITHI BHUSHAN TURAVI 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 63_Report - ADITHI BHUSHAN TURAVI 2022 Batch PES University EC.pdf already in database with 39 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 65_Report - Gagana.pdf\n",
      "============================================================\n",
      " 65_Report - Gagana.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 66_Report - CHETHAN V 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 66_Report - CHETHAN V 2022 Batch PES University EC.pdf already in database with 15 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 67_Report - NEERAJ R PATIL 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 67_Report - NEERAJ R PATIL 2022 Batch PES University EC.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 68_Report - CHINTHANA M.J 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 68_Report - CHINTHANA M.J 2022 Batch PES University EC.pdf already in database with 15 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 69_Report - vishal shivkumar.pdf\n",
      "============================================================\n",
      " 69_Report - vishal shivkumar.pdf already in database with 24 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 6_report - tanishka pasarad.pdf\n",
      "============================================================\n",
      " 6_report - tanishka pasarad.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 70_Report - Gowri Sriya.pdf\n",
      "============================================================\n",
      " 70_Report - Gowri Sriya.pdf already in database with 40 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 71_REPORT - SWATHI 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 71_REPORT - SWATHI 2022 Batch PES University EC.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 72_Report - Abhilash Vinod.pdf\n",
      "============================================================\n",
      " 72_Report - Abhilash Vinod.pdf already in database with 24 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 74_Report - Sowmya MN PESU-EC-CSE-PES2UG22CS820.pdf\n",
      "============================================================\n",
      " 74_Report - Sowmya MN PESU-EC-CSE-PES2UG22CS820.pdf already in database with 26 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 76_Report - Ankush Nagar PESU-EC-CSE-PES2UG21CS905.pdf\n",
      "============================================================\n",
      " 76_Report - Ankush Nagar PESU-EC-CSE-PES2UG21CS905.pdf already in database with 23 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 77_Report - Niveditha P.pdf\n",
      "============================================================\n",
      " 77_Report - Niveditha P.pdf already in database with 29 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 78_Report - Oshin Saraf.pdf\n",
      "============================================================\n",
      " 78_Report - Oshin Saraf.pdf already in database with 24 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 79_Report - Supratik Kar.pdf\n",
      "============================================================\n",
      " 79_Report - Supratik Kar.pdf already in database with 35 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 7_Report - khushi kiran.pdf\n",
      "============================================================\n",
      " 7_Report - khushi kiran.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 80_Report - PRAGNA PRASAD 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 80_Report - PRAGNA PRASAD 2022 Batch PES University EC.pdf already in database with 41 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 81_Report - NALLAPULA KARTHIK 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 81_Report - NALLAPULA KARTHIK 2022 Batch PES University EC.pdf already in database with 13 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 82_Report - Rakesh Raki.pdf\n",
      "============================================================\n",
      " 82_Report - Rakesh Raki.pdf already in database with 12 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 83_Report - Aaron Saldanha.pdf\n",
      "============================================================\n",
      " 83_Report - Aaron Saldanha.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 84_Report - Vismaya Ajikumar.pdf\n",
      "============================================================\n",
      " 84_Report - Vismaya Ajikumar.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 87_Report - AKSHIT PANDHARKAR 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 87_Report - AKSHIT PANDHARKAR 2022 Batch PES University EC.pdf already in database with 26 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 88_Report - Ananya Brahmavar.pdf\n",
      "============================================================\n",
      " 88_Report - Ananya Brahmavar.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 89_Report - Jay Shah.pdf\n",
      "============================================================\n",
      " 89_Report - Jay Shah.pdf already in database with 22 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 8_Report - NIKHIL SHAJI.pdf\n",
      "============================================================\n",
      " 8_Report - NIKHIL SHAJI.pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 90_Report - Aravind CeeBee.pdf\n",
      "============================================================\n",
      " 90_Report - Aravind CeeBee.pdf already in database with 20 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 91_Report - Chockalingam Annamalai.pdf\n",
      "============================================================\n",
      " 91_Report - Chockalingam Annamalai.pdf already in database with 10 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 92_Project_Report - raghavendra ambekar.pdf\n",
      "============================================================\n",
      " 92_Project_Report - raghavendra ambekar.pdf already in database with 31 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 93_Report - DARSH PATEL 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 93_Report - DARSH PATEL 2022 Batch PES University EC.pdf already in database with 26 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 94_Report - ASHWIN CHANDRASEKARAN 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 94_Report - ASHWIN CHANDRASEKARAN 2022 Batch PES University EC.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 95_Report - N P PRAGASHRI 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 95_Report - N P PRAGASHRI 2022 Batch PES University EC.pdf already in database with 18 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 96_capstone_report - RAJGOPAL VITHAL MUTNALI 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 96_capstone_report - RAJGOPAL VITHAL MUTNALI 2022 Batch PES University EC.pdf already in database with 18 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 97_Report - ALAN JOJI VELIYATH 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 97_Report - ALAN JOJI VELIYATH 2022 Batch PES University EC.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 98_Report - KEERTHANA R 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " 98_Report - KEERTHANA R 2022 Batch PES University EC.pdf already in database with 21 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: 99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " Processing: 99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf\n",
      " Total pages: 68\n",
      "â­  Skipping first 7 pages\n",
      "Processing pages 8 to 68 (61 pages)\n",
      "No text found\n",
      "Failed to extract meaningful text from 99_Report - T S SATHVIK NAG 2022 Batch PES University EC.pdf\n",
      "\n",
      "============================================================\n",
      "Processing: B10_REPORT - AADITYA DEV SHARMA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " B10_REPORT - AADITYA DEV SHARMA 2022 Batch PES University EC.pdf already in database with 13 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: capstone__team150_esa_report - SHREYAS V M 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " capstone__team150_esa_report - SHREYAS V M 2022 Batch PES University EC.pdf already in database with 16 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf already in database with 25 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team - 73_Report - Himanshu Nanda.pdf\n",
      "============================================================\n",
      " Team - 73_Report - Himanshu Nanda.pdf already in database with 38 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team-137_Capstone_Project_Report - Omprakash.pdf\n",
      "============================================================\n",
      " Team-137_Capstone_Project_Report - Omprakash.pdf already in database with 34 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team-43_Report - NITISH KUMAR REDDY K.pdf\n",
      "============================================================\n",
      " Team-43_Report - NITISH KUMAR REDDY K.pdf already in database with 19 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team18_Report - Swarnika Banerjee.pdf\n",
      "============================================================\n",
      " Team18_Report - Swarnika Banerjee.pdf already in database with 32 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team28_Report - Shweta Dash.pdf\n",
      "============================================================\n",
      " Team28_Report - Shweta Dash.pdf already in database with 27 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team35_report - ITISH RAJ SHUKLA 2022 Batch PES University EC.pdf\n",
      "============================================================\n",
      " Team35_report - ITISH RAJ SHUKLA 2022 Batch PES University EC.pdf already in database with 17 chunks\n",
      "\n",
      "============================================================\n",
      "Processing: Team64_Report - Meera Rao.pdf\n",
      "============================================================\n",
      " Team64_Report - Meera Rao.pdf already in database with 18 chunks\n",
      "\n",
      "======================================================================\n",
      " PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "Files processed: 23/152\n",
      "Total chunks stored: 489\n",
      "\n",
      "Summary:\n",
      "103_Report - TADISETTY SAI YASHWANTH 2022 Batch PES University EC.pdf: 27 chunks\n",
      "104_Report - Rahul28 Carasala.pdf: 28 chunks\n",
      "105_Report - Mayadevi Poojari.pdf: 17 chunks\n",
      "106_Report - Navya Pai.pdf: 19 chunks\n",
      "107_Report - SARANGA A KULKARNI 2022 Batch PES University EC.pdf: 25 chunks\n",
      "108_Report - dharini hindlatti.pdf: 14 chunks\n",
      "109_Report - Chandra Priya.pdf: 22 chunks\n",
      "110_Report - Vansheel Desai.pdf: 16 chunks\n",
      "111_REPORT - Srujan Vr.pdf: 13 chunks\n",
      "112_Report - Ashwin Sridhar.pdf: 14 chunks\n",
      "113_Report - Sujal S.pdf: 37 chunks\n",
      "115_Report - SHRUTI C.pdf: 20 chunks\n",
      "116_Report - rhea sheth.pdf: 20 chunks\n",
      "117_Report - Pratham Shetty.pdf: 19 chunks\n",
      "118_Report - MOHAMMED BASIM ALSM 2022 Batch PES University EC.pdf: 14 chunks\n",
      "119_Report - Harshan P.pdf: 23 chunks\n",
      "11_Report - ABHINAV B V 2022 Batch PES University EC (1).pdf: 27 chunks\n",
      "11_Report - ABHINAV B V 2022 Batch PES University EC.pdf: 27 chunks\n",
      "11_Report - ABHIRUP M V N S 2022 Batch PES University EC.pdf: 27 chunks\n",
      "120_Report - VIDULA.L.S. 2022 Batch PES University EC.pdf: 16 chunks\n",
      "122_Report - ADITHYA DARSHAN NAYAK 2022 Batch PES University EC.pdf: 15 chunks\n",
      "122_Report - SINCHANA HEBBAR 2022 Batch PES University EC.pdf: 19 chunks\n",
      "123_Report - monish d.pdf: 30 chunks\n"
     ]
    }
   ],
   "source": [
    "## Cell 10: Execute Processing\n",
    "\n",
    "# Check what PDFs are available\n",
    "print(\"Checking available PDFs...\")\n",
    "pdf_files = list_available_pdfs(\"./pdfs\")\n",
    "\n",
    "# Process all PDFs if any are found\n",
    "if pdf_files:\n",
    "    print(f\"\\n Starting processing of {len(pdf_files)} PDF files...\")\n",
    "    processed_files, total_chunks = process_all_pdfs(\"./pdfs\")\n",
    "else:\n",
    "    print(\"\\nTo get started:\")\n",
    "    print(\"1. Add your PDF files to the './pdfs' folder\")\n",
    "    print(\"2. Rerun this cell to process them\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f1ffbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing enhanced features:\n",
      "\n",
      " Testing chapter-specific search:\n",
      "ðŸ” Searching for: 'methodology'\n",
      "   With filters: {'chapter': '3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8953dc74eebd408f8ef932264fec2083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking 8 candidates...\n",
      " Found 8 candidates, 1 above threshold, returning top 1:\n",
      "\n",
      "1. 114_Report - Aditya S Joshi.pdf (ID: _chunk_2)\n",
      " Chapter 3\n",
      "   Initial: 0.614, Rerank: 1.938, Final: 1.541\n",
      "   Chunk size: 1797 chars\n",
      "   Preview: â€­CHAPTER 3â€¬\n",
      "â€­LITERATURE SURVEYâ€¬\n",
      "â€­Serialâ€¬\n",
      "â€­No.â€¬\n",
      "â€­Paper Nameâ€¬\n",
      "â€­Objectiveâ€¬\n",
      "â€­Methodologyâ€¬\n",
      "â€­Results andâ€¬\n",
      "â€­conclusionâ€¬\n",
      "â€­[1]â€¬\n",
      "â€­Deep Learningâ€¬\n",
      "â€­Algorithm forâ€¬\n",
      "â€­Threat Detectionâ€¬\n",
      "â€­in Hackers Forumâ€¬\n",
      "â€­(Deep Web)...\n",
      "\n",
      " Testing chatbot context building:\n",
      "ðŸ” Searching for: 'plant disease detection using GAN'\n",
      "Reranking 12 candidates...\n",
      " Found 12 candidates, 9 above threshold, returning top 3:\n",
      "\n",
      "1. 8_Report - NIKHIL SHAJI.pdf (ID: chunk_23)\n",
      "   Initial: 0.807, Rerank: 7.389, Final: 5.414\n",
      "   Chunk size: 1509 chars\n",
      "   Preview: 44 of 46\n",
      "REFERENCES/BIBLIOGRAPHY\n",
      "[1] P. Harinadha and C. Krishna Mohan, \"Leaf Based Tomato Plant Disease Detection Using\n",
      "Generated Images from WGP-ESR GAN,\" 2023 International Conference on Data Scien...\n",
      "\n",
      "2. 8_Report - NIKHIL SHAJI.pdf (ID: chunk_20)\n",
      "  Section 6.4\n",
      "   Initial: 0.826, Rerank: 7.176, Final: 5.271\n",
      "   Chunk size: 2981 chars\n",
      "   Preview: 35 of 46\n",
      "We aim to have an automated plant disease detection model while maintaining the accuracy of the\n",
      "prediction. The integration of GAN, the classification model, and the clustering model increase...\n",
      "\n",
      "3. 8_Report - NIKHIL SHAJI.pdf (ID: chunk_15)\n",
      "  Section 2.2\n",
      "   Initial: 0.802, Rerank: 5.019, Final: 3.754\n",
      "   Chunk size: 1925 chars\n",
      "   Preview: 29 of 46\n",
      "4) Scaling and Adaptability: We should be able to allow users to upload single or multiple\n",
      "photos for classification. We should also be able to show that the models will be finetuned in\n",
      "the f...\n",
      "Context preview:\n",
      "Based on the following highly relevant information from the documents:\n",
      "\n",
      "[Source 1: 8_Report - NIKHIL SHAJI.pdf - Relevance: 5.41]\n",
      "44 of 46\n",
      "REFERENCES/BIBLIOGRAPHY\n",
      "[1] P. Harinadha and C. Krishna Mohan, \"Leaf Based Tomato Plant Disease Detection Using\n",
      "Generated Images from WGP-ESR GAN,\" 2023 International Conference on Data Science and\n",
      "Network\n",
      "Security\n",
      "(ICDSNS),\n",
      "Tiptur,\n",
      "India,\n",
      "2023,\n",
      "pp.\n",
      "01-06,\n",
      "doi:\n",
      "10.1109/ICDSNS58469.2023.10245332.\n",
      "[2] Y. Zhao et al., \"Plant Disease Detection Using Generated Lea...\n",
      "\n",
      " Enhanced RAG system ready for chatbot integration!\n"
     ]
    }
   ],
   "source": [
    "# Your existing tests...\n",
    "\n",
    "# Add these new tests\n",
    "print(\"\\n Testing enhanced features:\")\n",
    "\n",
    "# Test filtered search\n",
    "print(\"\\n Testing chapter-specific search:\")\n",
    "chapter_search = search_similar_chunks(\n",
    "    \"methodology\", \n",
    "    n_results=2,\n",
    "    filter_dict={\"chapter\": \"3\"}  # Search only in chapter 3\n",
    ")\n",
    "\n",
    "# Test context building\n",
    "print(\"\\n Testing chatbot context building:\")\n",
    "context = build_context_for_chatbot(\"plant disease detection using GAN\", n_chunks=3)\n",
    "print(\"Context preview:\")\n",
    "print(context[:500] + \"...\")\n",
    "\n",
    "print(\"\\n Enhanced RAG system ready for chatbot integration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38624a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running comprehensive tests...\n",
      "\n",
      " Database Overview:\n",
      "Database Statistics:\n",
      " Total chunks stored: 3531\n",
      "  Documents stored: 43\n",
      "   Chapters identified: 208\n",
      "\n",
      "  Chunks per document:\n",
      "     â€¢ 100_Report - Raj Kiran.pdf: 23 chunks\n",
      "     â€¢ 101_Report - Deepti M P.pdf: 31 chunks\n",
      "     â€¢ 102_Report - Navaneeth krishnan R.pdf: 30 chunks\n",
      "     â€¢ 114_Report - Aditya S Joshi.pdf: 39 chunks\n",
      "     â€¢ 124_Report - ASHWINA RAKISH 2022 Batch PES University EC.pdf: 22 chunks\n",
      "     â€¢ 125_Report - Prisha Goel.pdf: 15 chunks\n",
      "     â€¢ 126_Report - ABHISHEK V SAGARNAL 2022 Batch PES University EC.pdf: 23 chunks\n",
      "     â€¢ 127_Report - Sathvik Srikanth.pdf: 28 chunks\n",
      "     â€¢ 128_Report - Manish Kumar.pdf: 19 chunks\n",
      "     â€¢ 129_Report - Nagaraj Sori.pdf: 23 chunks\n",
      "     â€¢ 12_Report - SUFIYAN PASHA 2022 Batch PES University EC.pdf: 21 chunks\n",
      "     â€¢ 130_Report - NAGAVENI L G 2022 Batch PES University EC.pdf: 34 chunks\n",
      "     â€¢ 131_Report - C A PRAJWAL 2022 Batch PES University EC.pdf: 16 chunks\n",
      "     â€¢ 132_Report - SAI SUDHIR SUNKU 2022 Batch PES University EC.pdf: 27 chunks\n",
      "     â€¢ 133_Report - S Saujanya.pdf: 27 chunks\n",
      "     â€¢ 135_Report - ADITYA PODDAR 2022 Batch PES University EC.pdf: 32 chunks\n",
      "     â€¢ 136_report - KARISHMA RAVI KUMAR 2022 Batch PES University EC.pdf: 25 chunks\n",
      "     â€¢ 138_Report - Rajeev Kalose.pdf: 19 chunks\n",
      "     â€¢ 139_Report - S Sai Sree Lakshmi.pdf: 19 chunks\n",
      "     â€¢ 13_Report - Urvashi Bhargava.pdf: 14 chunks\n",
      "     â€¢ 140_Report - Sumukh Suresh.pdf: 20 chunks\n",
      "     â€¢ 141_Report - sooraj suresh.pdf: 15 chunks\n",
      "     â€¢ 142_Report - ADITYA A S 2022 Batch PES University EC.pdf: 23 chunks\n",
      "     â€¢ 143-reportfile - MANOJ SOLAPURE.pdf: 30 chunks\n",
      "     â€¢ 144_Report - C H SRI CHARAN 2022 Batch PES University EC.pdf: 22 chunks\n",
      "     â€¢ 145_Report - DARSHAN PRASHAD SG 2022 Batch,PES University.pdf: 30 chunks\n",
      "     â€¢ 147_REPORT - Jagdish Malagond.pdf: 26 chunks\n",
      "     â€¢ 148_REPORT - E. Vinith Kumar reddy.pdf: 17 chunks\n",
      "     â€¢ 149_Report - Tirthraj Bhalodiya.pdf: 21 chunks\n",
      "     â€¢ 14_Report - Varun Kamath.pdf: 23 chunks\n",
      "     â€¢ 150_report - Parvati Bagewadi.pdf: 16 chunks\n",
      "     â€¢ 151_Report - NAMA SAI PRANAV 2022 Batch PES University EC.pdf: 20 chunks\n",
      "     â€¢ 152_Report - Arun Karthik S.pdf: 28 chunks\n",
      "     â€¢ 155_Report - SUDEEPGOWDA A S.pdf: 21 chunks\n",
      "     â€¢ 15_Report - Manish I.pdf: 34 chunks\n",
      "     â€¢ 16_Report - pooja s.pdf: 16 chunks\n",
      "     â€¢ 17_Report - Sidwin S.pdf: 21 chunks\n",
      "     â€¢ 19_Report - Maitreyi.pdf: 27 chunks\n",
      "     â€¢ 1_Report - JAWAHAR BALACHANDHER 2022 Batch PES University EC.pdf: 27 chunks\n",
      "     â€¢ 20_Report - NIHAL T M 2022 Batch PES University EC (1).pdf: 25 chunks\n",
      "     â€¢ 20_Report - NIHAL T M 2022 Batch PES University EC.pdf: 25 chunks\n",
      "     â€¢ 21_Report - Ranjana V.pdf: 25 chunks\n",
      "     â€¢ 22_Report - Siri.pdf: 1 chunks\n",
      "\n",
      " Sample stored chunks:\n",
      "Sample chunks (showing 3):\n",
      "\n",
      "1. 100_Report - Raj Kiran.pdf (Chunk 0)\n",
      "   Chapter 1\n",
      "   Section 3.1\n",
      "   Content: TABLE OF CONTENTS\n",
      "Chapter No.\n",
      "Title\n",
      "Page No.\n",
      "1.\n",
      "INTRODUCTION 1-3\n",
      "2.\n",
      "PROBLEM DEFINITION\n",
      "4-5\n",
      "3.\n",
      "LITERATURE SURVEY 6-13\n",
      "3.1 Paper -1: Evaluation Validity of Oral English Test App in Mobile\n",
      "Learning Envir...\n",
      "\n",
      "2. 100_Report - Raj Kiran.pdf (Chunk 1)\n",
      "   Section 1.1\n",
      "   Content: .\n",
      "Proposed platform has been engineered to address the different learning needs of students by\n",
      "integrating both the modern technology and proven educational methods. Thus, the result is a multi-\n",
      "dimen...\n",
      "\n",
      "3. 100_Report - Raj Kiran.pdf (Chunk 2)\n",
      "   Chapter 2\n",
      "   Content: __________________________________________________________________________________\n",
      "_____________________________________________________________________________________\n",
      "Dept. of CSE\n",
      "Jan - May, 2024\n",
      "Pa...\n",
      "\n",
      " Testing various search queries:\n",
      "\n",
      "==================================================\n",
      "Query: 'plant disease detection methodology'\n",
      "ðŸ” Searching for: 'plant disease detection methodology'\n",
      "Reranking 8 candidates...\n",
      " Found 8 candidates, 7 above threshold, returning top 2:\n",
      "\n",
      "1. 8_Report - NIKHIL SHAJI.pdf (ID: _chunk_2)\n",
      " Chapter 2\n",
      "  Section 3.1\n",
      "   Initial: 0.792, Rerank: 7.580, Final: 5.544\n",
      "   Chunk size: 2603 chars\n",
      "   Preview: 12 of 46\n",
      "CHAPTER 2\n",
      "Problem Definition\n",
      "The existing manual methods for plant disease detection in agriculture are inefficient and prone to\n",
      "errors, leading to significant loss of crops and are a huge co...\n",
      "\n",
      "2. 8_Report - NIKHIL SHAJI.pdf (ID: _chunk_0)\n",
      "  Section 3.1\n",
      "   Initial: 0.811, Rerank: 6.061, Final: 4.486\n",
      "   Chunk size: 2633 chars\n",
      "   Preview: 6 of 46\n",
      "TABLE OF CONTENTS\n",
      "Chapter No.\n",
      "Title\n",
      "Page No.\n",
      "1.\n",
      "INTRODUCTION\n",
      "11\n",
      "2.\n",
      "PROBLEM DEFINITION\n",
      "12\n",
      "3.\n",
      "LITERATURE SURVEY\n",
      "3.1 LEAFGAN: Data augmentation method for practical plant\n",
      "disease diagnosis\n",
      "3.2 Pl...\n",
      "\n",
      "==================================================\n",
      "Query: 'GAN architecture'\n",
      "ðŸ” Searching for: 'GAN architecture'\n",
      "Reranking 8 candidates...\n",
      " Found 8 candidates, 4 above threshold, returning top 2:\n",
      "\n",
      "1. 8_Report - NIKHIL SHAJI.pdf (ID: chunk_19)\n",
      "  Section 3.1\n",
      "   Initial: 0.758, Rerank: 4.035, Final: 3.052\n",
      "   Chunk size: 2254 chars\n",
      "   Preview: 34 of 46\n",
      "6.3.1 Design Description\n",
      "Our system mainly consists of four parts--preprocessing, the GAN Model, the Classification Model,\n",
      "and the clustering Model.\n",
      "In the first stage of the architecture, we...\n",
      "\n",
      "2. 15_Report - Manish I.pdf (ID: _chunk_0)\n",
      "  Section 3.2\n",
      "   Initial: 0.751, Rerank: 2.275, Final: 1.818\n",
      "   Chunk size: 1774 chars\n",
      "   Preview: TABLE OF CONTENTS\n",
      "Chapter No.\n",
      "Title\n",
      "Page No.\n",
      "1.\n",
      "INTRODUCTION\n",
      "01\n",
      "2.\n",
      "PROBLEM DEFINITION\n",
      "02\n",
      "3.\n",
      "LITERATURE SURVEY\n",
      "3.2 Artificial Intelligence Models for Urban Planning\n",
      "3.3 Building-GAN: Graph-Conditioned ...\n",
      "\n",
      "==================================================\n",
      "Query: 'machine learning classification'\n",
      "ðŸ” Searching for: 'machine learning classification'\n",
      "Reranking 8 candidates...\n",
      " Found 8 candidates, 4 above threshold, returning top 2:\n",
      "\n",
      "1. 19_Report - Maitreyi.pdf (ID: chunk_26)\n",
      "   Initial: 0.688, Rerank: 5.549, Final: 4.090\n",
      "   Chunk size: 2239 chars\n",
      "   Preview: .\n",
      "Machine learning models can be used for tasks like classification, regression, and\n",
      "clustering.\n",
      "â— RBF (Radial Basis Function): A real-valued function, the value of which\n",
      "depends only on the distance ...\n",
      "\n",
      "2. ProjectID_2_Report - AADITYA BISARIA 2022 Batch PES University EC.pdf (ID: chunk_23)\n",
      "   Initial: 0.706, Rerank: 5.475, Final: 4.044\n",
      "   Chunk size: 1548 chars\n",
      "   Preview: 21.\n",
      "Meta\n",
      "Contrastive\n",
      "Learning:\n",
      "A\n",
      "machine learning technique for learning\n",
      "representations\n",
      "by\n",
      "contrasting\n",
      "positive\n",
      "pairs\n",
      "against\n",
      "negative\n",
      "pairs\n",
      "in\n",
      "a\n",
      "high-dimensional space.\n",
      "22.\n",
      "ML: Machine Learning\n",
      "ML i...\n",
      "\n",
      "==================================================\n",
      "Query: 'results and evaluation'\n",
      "ðŸ” Searching for: 'results and evaluation'\n",
      "Reranking 8 candidates...\n",
      " Found 8 candidates, 2 above threshold, returning top 2:\n",
      "\n",
      "1. 53_Report - SATYAM KUMAR 2022 Batch PES University EC.pdf (ID: chunk_12)\n",
      "  Section 5.3\n",
      "   Initial: 0.654, Rerank: 3.142, Final: 2.396\n",
      "   Chunk size: 2471 chars\n",
      "   Preview: Page No.22\n",
      "â— Evaluation\n",
      "Our system will be able to do the evaluation process automatically by comparing\n",
      "the user selected answer and the correct answer and then proving the results to the\n",
      "users.\n",
      "â— Sec...\n",
      "\n",
      "2. 143-reportfile - MANOJ SOLAPURE.pdf (ID: chunk_27)\n",
      "   Initial: 0.656, Rerank: 2.765, Final: 2.132\n",
      "   Chunk size: 1618 chars\n",
      "   Preview: Jan - May, 2024\n",
      "Page No.2\n",
      "â€¢ Response Evaluation: One way to evaluate and assess the performance of a\n",
      "model is to use similarity metrics or classification accuracy while comparing the other\n",
      "labels as p...\n",
      "\n",
      "Testing chatbot context generation:\n",
      "\n",
      "Question: What is the methodology for plant disease detection?\n",
      "ðŸ” Searching for: 'What is the methodology for plant disease detection?'\n",
      "Reranking 12 candidates...\n",
      " Found 12 candidates, 10 above threshold, returning top 3:\n",
      "\n",
      "1. 8_Report - NIKHIL SHAJI.pdf (ID: _chunk_2)\n",
      " Chapter 2\n",
      "  Section 3.1\n",
      "   Initial: 0.786, Rerank: 7.044, Final: 5.166\n",
      "   Chunk size: 2603 chars\n",
      "   Preview: 12 of 46\n",
      "CHAPTER 2\n",
      "Problem Definition\n",
      "The existing manual methods for plant disease detection in agriculture are inefficient and prone to\n",
      "errors, leading to significant loss of crops and are a huge co...\n",
      "\n",
      "2. 8_Report - NIKHIL SHAJI.pdf (ID: chunk_14)\n",
      " Chapter 6\n",
      "  Section 6.1\n",
      "   Initial: 0.766, Rerank: 6.551, Final: 4.815\n",
      "   Chunk size: 1723 chars\n",
      "   Preview: 28 of 46\n",
      "CHAPTER 6\n",
      "System Design\n",
      "6.1 Current System\n",
      "The systems that exist for plant disease detection mainly follow a two-step process which is to identify\n",
      "if the plant is healthy or unhealthy using ...\n",
      "\n",
      "3. 8_Report - NIKHIL SHAJI.pdf (ID: chunk_10)\n",
      " Chapter 5\n",
      "  Section 5.1\n",
      "   Initial: 0.758, Rerank: 5.228, Final: 3.887\n",
      "   Chunk size: 1727 chars\n",
      "   Preview: 23 of 46\n",
      "CHAPTER 5\n",
      "Systems Requirements Specification\n",
      "5.1 Product Perspective\n",
      "5.1.1 Product Features\n",
      "1) Automated Disease Detection: Our plant disease detection model automatically detects plant\n",
      "disea...\n",
      "Context length: 6533 characters\n",
      "First 300 chars of context:\n",
      "Based on the following highly relevant information from the documents:\n",
      "\n",
      "[Source 1: 8_Report - NIKHIL SHAJI.pdf, Chapter 2, Section 3.1 - Relevance: 5.17]\n",
      "12 of 46\n",
      "CHAPTER 2\n",
      "Problem Definition\n",
      "The existing manual methods for plant disease detection in agriculture are inefficient and prone to\n",
      "errors, ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Comprehensive Testing\n",
    "print(\" Running comprehensive tests...\\n\")\n",
    "\n",
    "# 1. Database stats\n",
    "print(\" Database Overview:\")\n",
    "get_database_stats()\n",
    "\n",
    "# 2. Sample chunks\n",
    "print(\"\\n Sample stored chunks:\")\n",
    "show_sample_chunks(3)\n",
    "\n",
    "# 3. Test different search queries\n",
    "test_queries = [\n",
    "    \"plant disease detection methodology\",\n",
    "    \"GAN architecture\",\n",
    "    \"machine learning classification\",\n",
    "    \"results and evaluation\"\n",
    "]\n",
    "\n",
    "print(\"\\n Testing various search queries:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    results = search_similar_chunks(query, n_results=2)\n",
    "    \n",
    "# 4. Test chatbot context generation\n",
    "print(\"\\nTesting chatbot context generation:\")\n",
    "sample_questions = [\n",
    "    \"What is the methodology for plant disease detection?\",\n",
    "    \"How does the GAN model work in this system?\",\n",
    "    \"What are the evaluation metrics used?\"\n",
    "]\n",
    "\n",
    "for question in sample_questions[:1]:  # Just test one for brevity\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    context = build_context_for_chatbot(question, n_chunks=3)\n",
    "    print(f\"Context length: {len(context)} characters\")\n",
    "    print(\"First 300 chars of context:\")\n",
    "    print(context[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c3d0ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044135e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing current chunk sizes...\n",
      "\n",
      "Chunk size statistics:\n",
      "   Min: 1433 chars\n",
      "   Max: 2948 chars\n",
      "   Average: 2251 chars\n",
      "   Total chunks: 3531\n",
      "\n",
      "Size distribution:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk sizes look good!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Analyze Current Chunk Sizes\n",
    "print(\"Analyzing current chunk sizes...\\n\")\n",
    "\n",
    "# Get a sample of chunks\n",
    "sample = collection.get(limit=20)\n",
    "\n",
    "chunk_lengths = [len(doc) for doc in sample['documents']]\n",
    "print(f\"Chunk size statistics:\")\n",
    "print(f\"   Min: {min(chunk_lengths)} chars\")\n",
    "print(f\"   Max: {max(chunk_lengths)} chars\")\n",
    "print(f\"   Average: {sum(chunk_lengths)//len(chunk_lengths)} chars\")\n",
    "print(f\"   Total chunks: {collection.count()}\")\n",
    "\n",
    "# Show distribution\n",
    "print(f\"\\nSize distribution:\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist([len(doc) for doc in collection.get(limit=100)['documents']], bins=20)\n",
    "plt.xlabel('Chunk Size (characters)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Chunk Sizes')\n",
    "plt.show()\n",
    "\n",
    "# Check if chunks are too small\n",
    "small_chunks = [l for l in chunk_lengths if l < 500]\n",
    "if len(small_chunks) > len(chunk_lengths) * 0.3:\n",
    "    print(\"\\n WARNING: Many chunks are small! Consider reprocessing with larger chunk_size.\")\n",
    "else:\n",
    "    print(\"\\nChunk sizes look good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0207690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_database():\n",
    "    \"\"\"Clear all data from the database\"\"\"\n",
    "    try:\n",
    "        count_before = collection.count()\n",
    "        if count_before == 0:\n",
    "            print(\"  Database is already empty\")\n",
    "            return\n",
    "            \n",
    "        response = input(f\" Delete all {count_before} chunks? Type 'YES' to confirm: \")\n",
    "        if response == 'YES':\n",
    "            # Get all IDs\n",
    "            all_ids = collection.get()['ids']\n",
    "            if all_ids:\n",
    "                collection.delete(ids=all_ids)\n",
    "                print(f\" Deleted {count_before} chunks from collection\")\n",
    "            \n",
    "            # Verify it's empty\n",
    "            count_after = collection.count()\n",
    "            print(f\" Collection now has {count_after} chunks\")\n",
    "        else:\n",
    "            print(\" Operation cancelled\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing database: {e}\")\n",
    "\n",
    "# Test the function\n",
    "#clear_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "948e2025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['100_Report - Raj Kiran.pdf_chunk_0',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_1',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_2',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_3',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_4',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_5',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_6',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_7',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_8',\n",
       "  '100_Report - Raj Kiran.pdf_chunk_9'],\n",
       " 'embeddings': array([[-0.00563105,  0.0167183 , -0.01310646, ...,  0.00573733,\n",
       "         -0.01237135, -0.02724457],\n",
       "        [ 0.02623169, -0.00910875,  0.03407014, ...,  0.0274118 ,\n",
       "         -0.00687096,  0.00705954],\n",
       "        [ 0.01550307,  0.02868799, -0.00468095, ...,  0.02589978,\n",
       "         -0.00010401, -0.01030831],\n",
       "        ...,\n",
       "        [-0.02059907,  0.01253679, -0.03398529, ...,  0.02452859,\n",
       "         -0.00994088, -0.00088712],\n",
       "        [-0.00190948,  0.02241377, -0.00857191, ...,  0.00472537,\n",
       "         -0.0561363 , -0.00481184],\n",
       "        [-0.00715812,  0.04823392, -0.01307459, ..., -0.01138991,\n",
       "         -0.04188026, -0.04854847]], shape=(10, 768)),\n",
       " 'documents': ['TABLE OF CONTENTS\\nChapter No.\\nTitle\\nPage No.\\n1.\\nINTRODUCTION 1-3\\n2.\\nPROBLEM DEFINITION\\n4-5\\n3.\\nLITERATURE SURVEY 6-13\\n3.1 Paper -1: Evaluation Validity of Oral English Test App in Mobile\\nLearning Environment\\nPaper -2: Progress Tracking and Responding to Online Public Shaming\\nEvents on Twitter\\n3.2 Paper -3: A 3D Board Game Using a Randomized Algorithm and AI\\nto Improve EnglishVocabulary Retention and Fluency\\nPaper -4: Effects of an automatic speech recognition system with peer\\nfeedback on pronunciationinstruction for adults\\n3.3 Paper -5: English to Meiteilon Machine Translation Using Seq2Seq with\\nLong Short-Term Memory\\nPaper -6: English Online Learning Platform Based on Mobile Android App\\n3.4 Paper -7: Personalized Adaptive Learning Technologies Based on Machine\\nLearning Techniques to Identify Learning Styles: A Systematic Literature Review\\nPaper -8: From Digital Learning Resources to Adaptive Learning\\n4.\\nDATA 14-16\\n4.1 Overview\\n4.2 Dataset\\n5.\\nSYSTEM REQUIREMENTS SPECIFICATION\\n17-23\\n6.\\nSYSTEM DESIGN\\n24-41\\n7.\\nCONCLUSION OF CAPSTONE PROJECT PHASE - 1\\n42\\n8.\\nPLAN OF WORK FOR CAPSTONE PROJECT PHASE - 2 43\\nREFERENCES 43-44\\nAPPENDIX A DEFINITIONS, ACRONYMS, AND ABBREVIATIONS 45\\n\\nLIST OF FIGURES\\nFigure No.\\nTitle\\nPage No.\\n6.1 High Level Architecture Design Diagram 24\\n6.2 Master Class Diagram 26\\n6.3 Entity -Relationship Diagram 31\\n6.4 Use Case Diagram 34\\n6.5 Deployment Diagram 38\\n\\n__________________________________________________________________________________\\n_____________________________________________________________________________________\\nDept. of CSE\\nJan - May, 2024\\nPage No.1\\nCHAPTER 1\\nINTRODUCTION\\nIn an age where the world is getting globalized and interconnectedness is the main trend, expertise in\\nEnglish is the important ability for the persons who need to achieve success in both academic career\\nand career. The fact that the person will be able to communicate effectively in English will not only\\nopen the opportunity for him/her to study and career advancement but also he/she will learn to live and\\nwork across various countries during his/her academic and professional life. On the other hand,\\nlearning a new language may be a heroic effort with language proficiency levels among the barriers,\\nvarious learning styles, and not many options for quality learning resources. Taking into account these\\ndifficulties our capstone project aims to develop a new English teaching platform that seeks to get\\nthrough the regular restrictions and assists to students with a rich and highly involved learning\\nenvironment',\n",
       "  \".\\nProposed platform has been engineered to address the different learning needs of students by\\nintegrating both the modern technology and proven educational methods. Thus, the result is a multi-\\ndimensional step toward the goal of language proficiency. With the help of digital tools and resources\\nlike multimedia, we envisage providing a platform for language learning, where everyone can study\\nEnglish in an easy but effective and fun way. Underpinning our platform's service is the dedication to\\ndeliver personalized learning and improvements. We are aiming to achieve this by creating\\npersonalized learning paths with the help of innovative tools such as adaptive learning and real-time\\nfeedback systems, so that every learner will be able to tune into his/her own learning needs and\\npreferences, thus ultimately reaching the best results and maintaining high levels of motivation\\nthroughout the learning experience.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.2\\nBesides, our platform does not just present a static information set, as it is a dynamic ecological\\nenvironment that responds to the user reviews and language learning trends. We strive to establish a\\ncommunity that is all about teamwork, modernization, and new technology and hope our platform\\nnever gets behind the tide of time. In the end, we would like our English learning platform to be\\nregarded as our move forward to the dream of education equality in English.\\n1.1 Overview\\nThe goal of our senior work is to create a useful English teaching platform that is able to cope with the\\nindividuality of all students in the world. Integrating state-of-the-art technology with researchbased\\ninstructional methods, our platform multiplies the number of tools for teaching languages and learning\\nto up to the mark.\\nKey features ;\\nâ€¢ Translation Integration: Smooth meshing in of translation equipments for users to\\nimprove understanding.\\nâ€¢ Online Assessments: Besides, Smart tests that respond to different learning types for\\ntailored evaluation.\\nâ€¢ Multimedia Resources: Engaging content, like scenes from movies to support cultural\\nimmersion and get clear understanding of the message.\\nâ€¢ Voice Assistant for Pronunciation Feedback: Instant feedback to promote the English\\nspeaking skills.\",\n",
       "  \"__________________________________________________________________________________\\n_____________________________________________________________________________________\\nDept. of CSE\\nJan - May, 2024\\nPage No.3\\nâ€¢ Adaptive Learning Paths: Personalized learning pathways designed to meet each\\nstudent where they're at in their progress and ability to learn.\\nâ€¢ Immersive Learning Experience: Interactive simulation and virtual environment to\\nenable continuity of the knowledge process.\\nâ€¢ Progress Tracking: Effective tools for tracking and assessment of performance as well\\nas pinpointing problematic areas.\\nâ€¢ Continuous Improvement: Updating after collecting users feedback and data analysis\\nfor efficient features over time.\\nBy the means of technology and pedagogy our English learning program intends to democatize\\naccess to best quality language courses enabling learners with the skills and confidence necessary to\\nsuccessfully operate in a connected and global world.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.4\\nCHAPTER 2\\nPROBLEM DEFINITION\\nWhile there are already English learning apps available, they also have several weaknesses such as\\nneglecting the translation features, creating basic online assessments and lack of pronunciation\\ncorrectors by means of the voice assistant. Such flaws prevent peer-to-peer language proficiency, which\\nhampers them in the process they become inhabitants of the globalized world. For this problem to be\\nsolved, it is, therefore, mandatory to come up with a high-level Constructive English Learning Platform\\nbuilt on AI algorithms. This platform aims to fill the existing gaps in English language learning by\\nproviding convenient features to learners' unique styles and abilities regardless of their English\\nproficiency level. The core features involve advanced translation services, multifaceted and changeable\\nevaluations, immersive multimedia resources, and a conversational caretaking voice assistant.\\nkey points:\\nâ€¢ Deficiencies in Existing Apps: Shading of the shortcomings that modern language learning\\nsoftware poses, for example, incomplete features and limited interactivity.\\nâ€¢ Impact on Language Proficiency: The accentuation of the shortfalls which impede learners from\\ngaining far-reaching knowledge of the language will in turn curb their ability to participate\\nactively in academic and professional undertakings.\\nâ€¢ Need for Advanced Solution: Firstly, there is a clear need for an AI-based, advanced\\nConstructive English Learning Platform (CELP) that is able to address the shortcomings of\\nexisting curriculums effectively.\",\n",
       "  '__________________________________________________________________________________\\n_____________________________________________________________________________________\\nDept. of CSE\\nJan - May, 2024\\nPage No.5\\nKey Components of the Solution: The system considers the basic elements that the platform in question\\nis supposed to comprise, such as embedded translation services, various evaluation methods, enriched\\nmultimedia resources, and a user friendly voice assistant.\\nBy delimiting the problem statement in this manner we do create an evidently clear place of\\nunderstanding of the staggering difficulties that learners experience in current English language\\neducation. It is also clear that an innovative solution must be created to address all these issues\\ncomprehensively.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.6\\nCHAPTER 3\\nLITERATURE SURVEY\\nPaper 1: Evaluation Validity of Oral English Test App in Mobile Learning Environment\\nPaper 2: Progress Tracking and Responding to Online Public Shaming Events on Twitter\\nObjective of the Paper:\\nThe paper will analyze the ways of progress monitoring in the foreign-languages level,\\npaying more attention to the application of the tests as one of the main evaluation tools.\\nTechniques/Methods:\\nThe essay utilizes tests as a pacesetter for realizing the English language talent.\\nModels Used:\\nâ€¢ Multi Facet Rasch Model (MFRM): It serves as an indicator of progress when it comes\\nto different sides of language learning skills.\\nâ€¢ Single Activity Progress (SAP): For example, the tracking of learning progress in\\nlanguage activities that are focused around a specific purpose.',\n",
       "  '__________________________________________________________________________________\\n_____________________________________________________________________________________\\nDept. of CSE\\nJan - May, 2024\\nPage No.7\\nAdvantages:\\nâ€¢ Divides candidates into two groups those with high perform results and those with\\nlow perform results.\\nâ€¢ Is capable of conducting fine resolution progress registration analyzing separate\\ncomponents.\\nDisadvantages:\\nâ€¢ Sensitive to overfitting and with a higher chance of overfitting when working with\\ncomplex data.\\nâ€¢ Lack of transparency for making interpretation and consistent results in the face\\nof small alterations in data.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.8\\nPaper 3 : A 3D Board Game Using a Randomized Algorithm and AI to Improve English\\nVocabulary Retention and Fluency\\nPaper 4 : Effects of an automatic speech recognition system with peer feedback on\\npronunciation instruction for adults\\nObjective of the Paper:\\nThe intent of this research is to investigate immersive learning procedures in English Language\\nstudies notably through the utilization of games. This paper addresses using games in the\\nlearning process, which considers grammar and vocabulary, as well as pronunciation feedback\\nfrom Automatic Speech Recognition (ASR) models.\\nTechniques/Methods:\\nThe essay employs games as the medium to the learning processes that are immersive in the\\nEnglish language education.\\nGames are constructed to enhance these language skills; grammar, vocabulary, and\\npronunciation.\\nObjective: The task of ASR in my action includes reading the given text and speaking it\\naloud.',\n",
       "  '__________________________________________________________________________________\\n_____________________________________________________________________________________\\nDept. of CSE\\nJan - May, 2024\\nPage No.9\\nAdvantages:\\nâ€¢ Games give users learn words, this is one of the skills in English\\nlearning.\\nâ€¢ AI enhances the learning process by means of dialogue platforms, where learners can\\nreceive the sound feedback.\\nLimitations:\\nâ€¢ No cloud database for the opening of new gaming scenarios, improving the\\ngaming and education.\\nâ€¢ ASR tools exhibit limitations on phonetic transcription which they have not yet\\nacquired. Although with remarkable improvement, ASR machines are still inferior\\ntowards humans in terms of the accuracy evaluation.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.10\\nPaper 5: English to Meiteilon Machine Translation Using Seq2Seq with Long Short-Term\\nMemory\\nPaper 6: English Online Learning Platform Based on Mobile Android App\\nObjective of the Paper:\\nThe main purpose of this work is to sketch out the implementation of the NMT models that can\\nbe used for a mobile app of Android type. Actually, I build the paper on top of Seq2Seq models with\\nLSTM architecture that enables our application to translate. Also, the paper strives to combine a set of\\noptions within the app, i.e. User Management, Video-on-demand, Online-test, translation function, and\\npersonalized recommendation algorithm.\\nTechniques/Methods:\\nTranslation using NMT Models:\\nAn application process using NMT models translates texts for various tasks that are mobile and operate\\non Android.\\nDesign of Seq2Seq model with LSTM structure, the machine learning approach for translation\\ninto the target language.\\nMobile Android App:\\nThe creation of an Android application that will bring into usage language translation services.\\nA module will also be built made from User Management, VOD, Online Test, Translation\\nFunction and Personalized Recommendation Algorithm.\\n\\n__________________________________________________________________________________\\n_____________________________________________________________________________________\\nDept. of CSE\\nJan - May, 2024\\nPage No.11\\nAdvantages:\\nâ€¢ Better sensitivity and smoothness, machine translations are gaining.\\nâ€¢ Intergration of the rest features into a single platform, to improve UI and make the whole\\naffair more simple.\\nLimitations:\\nâ€¢ Overfitting of accuracy.\\nâ€¢ The issue of quality and datasets is one of the areas where AI faces challenges.\\nâ€¢ While dealing with the idiomatic phrases and the cultural and language subtleties.\\nâ€¢ Students who arenâ€™t used to encountering rare or new vocabulary during reading will\\nhave a greater chance of comprehending similar technical terminology brought up in\\ntheir STEM courses.\\nâ€¢ Connectivity issues and mobile device compatibility issues.',\n",
       "  \"Dept. of CSE\\nJan - May, 2024\\nPage No.12\\nPaper 7: Personalized Adaptive Learning Technologies Based on Machine Learning Techniques\\nto Identify Learning Styles: A Systematic Literature Review\\nPaper 8: From Digital Learning Resources to Adaptive Learning Objects\\nObjective of the Paper:\\nThe purpose of the paper is to analyze the process of constructing of a personalized adaptive learning\\nsystem with the help of Learning Style Models (LSMs) and the recommendation systems. The research\\ndeals with assigning classifications of Learning Styles (LSs) to individuals and providing personalized\\nlearning content using recommendation systems that are tailored to unique learner characteristics.\\nTechniques/Methods:\\nClassification of Learning Styles: Implementation of the FSLSM model to assign students into\\nparticular styles of learning. Detecting and storing of LSs for the recommendation system in\\nlearners' profiles.\\nRecommendation System:\\nA personalized learning content which is adapted by the use of recommendation system of the\\nappropriate individual learner characteristics.\\nDescription of Learning Content:\\nEstablishment of the learning content within adaptive hypermedia educational systems as a core of\\npersonalized e-learning.\\nThe conversation will be about the progress of digital learning materials from their naked form to\\nindividualized adaptive learning objects tuned to various users' characteristics.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.13\\nAdvantages:\\nâ€¢ Improvement in learning speed and productivity with the reduction in cognitive disturbance\\nsymptoms.\\nâ€¢ Enable provision of a perfect learning sequence and content that is tailored to learner\\nknowledge.\\nâ€¢ Utilization of FSLSM for classifying users as per their mode of learning.\\nâ€¢ Classification of resources into different units (learning objects) for users to view them in\\nrecommendation page.\\nLimitations:\\nâ€¢ Management of a personal profile as a manager of static and dynamic information about the\\nlearner, updating and improving the learner model after each learning process or assessment.\\nâ€¢ Lack of possibilities to recommend multimedia resources which donâ€™t have user input.\\nâ€¢ The difficulty lies in the personalization of the delivery process in which the same content is\\nwatched or read by diverse users. Therefore, the adaptivity must be adjusted according\",\n",
       "  'Dept. of CSE\\nJan - May, 2024\\nPage No.14\\nCHAPTER 4\\nDATA\\n4.1 Overview\\nFor our project we are using two sets of dataset, Applicant dataset which contains the information about\\neach Applicant like their skills, previous salary if any, years of experience and so on and other one is Job\\ndescription dataset which describes the roles which the HRâ€™s want to recruit, the location of the job and\\nso on.\\nTranslation Features:\\nIt is necessary to build an effective translation feature with a large amount of data as a bilingual corpus\\nof datas. This corpus consists of pairs of texts or sentences in two languages: the pairing of the source\\nlanguage and the target language. The source language text appears in the second line and the third line\\ncontains the translation in the target language. Bilingual corpus is a cornerstone for training various kinds\\nof translation models, namely Neural Machine Translation (NMT).\\nIt is the level of quality and the variety of the bilingual dataset that largely determines the success of\\ntranslation models. It needs to cover a wide range of topics, domains, and writing styles so the model can\\nserve as an efficient translator for any kind of text. Furthermore, we should diversify the corpus by adding\\nlanguage of different level of formality, for instance, the technical terms, idiomatic expressions as well\\nas dial\\nects to make a model applicable to any environment.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.15\\nThe bilingual corpus metadata can be a really beneficial source for better translation algorithm\\ntuning. Language tags indicate that each text within the corpus belongs to one language or another, thus\\nhelping specific language processing. Domain labels group texts by their subject or sector spectrum, and\\nthis makes the development of models for domain-specific translation possible.\\nPronunciation Features:\\nData for pronunciation features heavily depend on speech data. This involves, speakers utterances in the\\ntarget language with a carrying text transcriptions in the same language. The speech input needs to be\\nrecorded under different phonetic contexts, accents, speaking styles, and speech rates, so the model can\\ncorrectly capture and assess the different speech patterns.\\nBeside raw audio recordings and transcripts the annotations facilitate to have an even better dataset and\\nboost the performance of models. Annotations can include different stress patterns to distinguish between\\nthe stressed and unstressed syllables of a word, the boundaries of phonemes highlighting the boundaries\\nof individual speech sounds and prosodic features like intonation and rhythm.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.16\\n4.2 Dataset\\nEnglish to France\\nEnglish to Hindi',\n",
       "  \"Dept. of CSE\\nJan - May, 2024\\nPage No.16\\n4.2 Dataset\\nEnglish to France\\nEnglish to Hindi\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.17\\nCHAPTER 5\\nSYSTEM REQUIREMENTS SPECIFICATION\\n5.1 Functional Requirements\\n1. Data Collection\\nâ€¢\\nGather variety of data that is related to learning of the English language, like\\nuser translation, pronunciation, results of test, and feedback.\\nâ€¢\\nCreate a complete database in order to store this important data and guarantee\\nits consistent updates and security.\\n2. Data Validation and Cleaning\\nâ€¢\\nVerify data for the correctness and compatibility, thus keeping learning\\nmaterials reliable and the standards accepted.\\nâ€¢\\nTake out all those confusing, duplicated and unnecessary information, so the\\nlearners will have only the genuine experience of learning.\\n3. Feature Extraction\\nâ€¢\\nDiscover the main features of learning data, e.g. the wording used, the structures\\nof grammar, and the patterns of pronunciation.\\nâ€¢\\nDesign tools to pull contextual elements from the learning materials that\\nconcern the effective language learning content.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.18\\n4. Machine Learning Processing\\nâ€¢\\nUse machine learning techniques to analyze language learning data and see\\nif there are any patterns in the behavior of users and also how they are\\nprogressing.\\nâ€¢\\nUse of this analysis helps you to give personal suggestions, user specific\\nrecommendations and adaptive learning paths for each user.\\n5. Recommendation Generation\\nâ€¢\\nDevelop tailored suggestions for learning resources, exercises, and activities\\nrelative to user profile, expertise, and desired learning goals.\\nâ€¢\\nUse machine learning outputs to propose appropriate content and learning\\ntactics that can fit in each individual's objectives and requirements.\\n6. Privacy Protection\\nâ€¢\\nImplement actions to preserve the user privacy and guarantee the safety of the\\npersonal data while working within the platform.\\nâ€¢\\nEncrypt and anonymize all sensitive information and implement additional\\naccess controls procedures to reduce the risk of information leakage.\\n7. User Feedback Incorporation\\nâ€¢\\nInclude tools for learners to offer input on the learning journey such as the\\nsuitability of the subject matter, difficulty level, and the overall learner\\nsatisfaction.\\nâ€¢\\nApply this feedback in permanently perfecting the platform, refining the\\nrecommendations, highlighting the content offerings, and adjusting the user\\ninterface based on user comments.\",\n",
       "  'Dept. of CSE\\nJan - May, 2024\\nPage No.19\\n8. Output Presentation\\nâ€¢\\nDisplay a detailed learning information such as suggests, progress notes and\\nrecommendations through the user friendly interface which anyone can use.\\nâ€¢\\nStrive to make learning materials simple, and interesting, as this will help the\\nlearning process, and create better decision-making for the users.\\n5.2 External Interface Requirements\\n5.2.1 User Interfaces\\nâ€¢\\nThe UI that is applied for the English learning platform is the graphical\\nuser interface (GUI) design that has made an impact towards user-\\nfriendly and professional standards. It makes sure that the items remain\\nthe same and have an element of being familiar for users.\\nâ€¢\\nThese modules include a user support section and a search component of\\nthe platform to improve interactions with the product and consequently,\\nuser satisfaction.\\nâ€¢\\nInstant update calls for timely posts of content materials and becoming\\nrecipients of usersâ€™ interaction minimizing interruption and improving\\nusersâ€™ experience\\nallin-all.\\n\\nDept. of CSE\\nJan - May, 2024\\nPage No.20\\nâ€¢\\nProvided with straightforward small buttons or predefined programs is\\nmeant for instantaneous interaction with the system, hence the\\nconvenience and efficiency are guaranteed.\\nâ€¢\\nVery informative and error-messages are designed to guide the users so\\nthat they can understand and resolve the encountered errors in the most\\neffective manner.\\n5.2.2 Hardware Requirements\\nâ€¢\\nA learning platform of English is created that can be used on all possilble\\ndevices such as desktops, laptops, tablets, and smartphones and this\\nwould again entitle the users.\\nâ€¢\\nTransmission protocols are unified to make the transferring process of\\ninformation between the application software and hardware components\\nsmoother. This optimizes the performance and reliability.\\nâ€¢\\nSoftware developers put hardware components like processors and\\nmemory to work to allow saftet processsing and storage of data\\neffectively.\\nâ€¢\\nTaking forward into the future with the possibility of the infusion of the\\nperipherals it could become one cohesive system rather than a set of\\nperipherals, and the users will not only get an immersive experience but\\nalso will be able to assimilate things fast.'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'section': '3.1',\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'preview': 'TABLE OF CONTENTS Chapter No. Title Page No. 1. INTRODUCTION 1-3 2. PROBLEM DEFINITION 4-5 3. LITERATURE SURVEY 6-13 3.1 Paper -1: Evaluation Validity of Oral English Test App in Mobile Learning Envir',\n",
       "   'position_ratio': 0.0,\n",
       "   'word_count': 375,\n",
       "   'total_chunks': 23,\n",
       "   'chunk_length': 2542,\n",
       "   'chapter': '1',\n",
       "   'chunk_id': 0,\n",
       "   'potential_title': 'TABLE OF CONTENTS'},\n",
       "  {'section': '1.1',\n",
       "   'position_ratio': 0.043478260869565216,\n",
       "   'chunk_id': 1,\n",
       "   'total_chunks': 23,\n",
       "   'preview': '. Proposed platform has been engineered to address the different learning needs of students by integrating both the modern technology and proven educational methods. Thus, the result is a multi- dimen',\n",
       "   'word_count': 347,\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'chunk_length': 2247},\n",
       "  {'position_ratio': 0.08695652173913043,\n",
       "   'chunk_length': 2570,\n",
       "   'chunk_id': 2,\n",
       "   'total_chunks': 23,\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'preview': '__________________________________________________________________________________ _____________________________________________________________________________________ Dept. of CSE Jan - May, 2024 Pa',\n",
       "   'word_count': 346,\n",
       "   'chapter': '2'},\n",
       "  {'word_count': 227,\n",
       "   'total_chunks': 23,\n",
       "   'preview': '__________________________________________________________________________________ _____________________________________________________________________________________ Dept. of CSE Jan - May, 2024 Pa',\n",
       "   'chunk_id': 3,\n",
       "   'position_ratio': 0.13043478260869565,\n",
       "   'chapter': '3',\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'chunk_length': 1615},\n",
       "  {'chunk_id': 4,\n",
       "   'preview': '__________________________________________________________________________________ _____________________________________________________________________________________ Dept. of CSE Jan - May, 2024 Pa',\n",
       "   'word_count': 222,\n",
       "   'total_chunks': 23,\n",
       "   'position_ratio': 0.17391304347826086,\n",
       "   'chunk_length': 1600,\n",
       "   'source': '100_Report - Raj Kiran.pdf'},\n",
       "  {'chunk_length': 2803,\n",
       "   'position_ratio': 0.21739130434782608,\n",
       "   'preview': '__________________________________________________________________________________ _____________________________________________________________________________________ Dept. of CSE Jan - May, 2024 Pa',\n",
       "   'total_chunks': 23,\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'chunk_id': 5,\n",
       "   'word_count': 388},\n",
       "  {'source': '100_Report - Raj Kiran.pdf',\n",
       "   'position_ratio': 0.2608695652173913,\n",
       "   'chunk_length': 2333,\n",
       "   'chunk_id': 6,\n",
       "   'preview': 'Dept. of CSE Jan - May, 2024 Page No.12 Paper 7: Personalized Adaptive Learning Technologies Based on Machine Learning Techniques to Identify Learning Styles: A Systematic Literature Review Paper 8: F',\n",
       "   'word_count': 338,\n",
       "   'total_chunks': 23},\n",
       "  {'preview': 'Dept. of CSE Jan - May, 2024 Page No.14 CHAPTER 4 DATA 4.1 Overview For our project we are using two sets of dataset, Applicant dataset which contains the information about each Applicant like their s',\n",
       "   'chunk_id': 7,\n",
       "   'section': '4.1',\n",
       "   'total_chunks': 23,\n",
       "   'word_count': 430,\n",
       "   'chunk_length': 2705,\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'position_ratio': 0.30434782608695654,\n",
       "   'chapter': '4'},\n",
       "  {'source': '100_Report - Raj Kiran.pdf',\n",
       "   'chunk_length': 2430,\n",
       "   'section': '4.2',\n",
       "   'position_ratio': 0.34782608695652173,\n",
       "   'preview': 'Dept. of CSE Jan - May, 2024 Page No.16 4.2 Dataset English to France English to Hindi  Dept. of CSE Jan - May, 2024 Page No.17 CHAPTER 5 SYSTEM REQUIREMENTS SPECIFICATION 5.1 Functional Requirements ',\n",
       "   'chunk_id': 8,\n",
       "   'total_chunks': 23,\n",
       "   'word_count': 369,\n",
       "   'chapter': '5'},\n",
       "  {'word_count': 344,\n",
       "   'preview': 'Dept. of CSE Jan - May, 2024 Page No.19 8. Output Presentation â€¢ Display a detailed learning information such as suggests, progress notes and recommendations through the user friendly interface which ',\n",
       "   'position_ratio': 0.391304347826087,\n",
       "   'chunk_id': 9,\n",
       "   'section': '5.2',\n",
       "   'chunk_length': 2228,\n",
       "   'source': '100_Report - Raj Kiran.pdf',\n",
       "   'total_chunks': 23}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek()  # Or use collection.get() to see chunk IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d8f62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Total documents in collection: 3531\n"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸ“¦ Total documents in collection: {collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f721e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Collection name: rag-chunks\n",
      "ðŸ“¦ Total documents: 3531\n",
      "ðŸ§ª Client type: <class 'chromadb.api.client.Client'>\n",
      "ðŸ“ DB location : C:\\Users\\rohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\chromadb\\api\\client.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"ðŸ“‚ Collection name:\", collection.name)\n",
    "print(\"ðŸ“¦ Total documents:\", collection.count())\n",
    "\n",
    "# Inspect client object to confirm it's a PersistentClient\n",
    "print(\"ðŸ§ª Client type:\", type(chroma_client))\n",
    "\n",
    "# Optional: Look into where it's storing (if PersistentClient)\n",
    "print(\"ðŸ“ DB location :\", inspect.getsourcefile(type(chroma_client)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf465273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path: c:\\Users\\rohan\\Desktop\\chatbot\\999\\vector_db_july500\n",
      "Current working directory: c:\\Users\\rohan\\Desktop\\chatbot\\999\n",
      "Files in vector_db_july500: ['bd1033ab-fc9a-4d61-9330-4d5e9d5db8fa', 'chroma.sqlite3']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get absolute path\n",
    "abs_path = os.path.abspath(\"vector_db_july500\")\n",
    "print(f\"Absolute path: {abs_path}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if the directory exists and what's in it\n",
    "if os.path.exists(\"vector_db_july500\"):\n",
    "    files = os.listdir(\"vector_db_july500\")\n",
    "    print(f\"Files in vector_db_july500: {files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c52f9fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path: c:\\Users\\rohan\\Desktop\\chatbot\\999\\vector_db_july500\n",
      "Current working directory: c:\\Users\\rohan\\Desktop\\chatbot\\999\n",
      "Files in vector_db_july500: ['bd1033ab-fc9a-4d61-9330-4d5e9d5db8fa', 'chroma.sqlite3']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get absolute path\n",
    "abs_path = os.path.abspath(\"vector_db_july500\")\n",
    "print(f\"Absolute path: {abs_path}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if the directory exists and what's in it\n",
    "if os.path.exists(\"vector_db_july500\"):\n",
    "    files = os.listdir(\"vector_db_july500\")\n",
    "    print(f\"Files in vector_db_july500: {files}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
