This paper comes to the conclusion that while LLMs like GPT-4 show potential for automated essay evaluation, their current limitations, such as hallucinations, misaligned feedback, and over-reliance on prompts, make them less reliable for nuanced academic assessments. Hence, we need to focus on improving the LLMs rubric assessment and develop domain specific datasets which will solve this problem and LLMs could be used to streamline assessment processes.